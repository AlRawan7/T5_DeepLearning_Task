{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cda1ba95",
   "metadata": {},
   "source": [
    "# Exam on Artificial Neural Networks (ANN)\n",
    "\n",
    "Welcome the Artificial Neural Networks (ANN) practical exam. In this exam, you will work on a classification task to predict the outcome of incidents involving buses. You are provided with a dataset that records breakdowns and delays in bus operations. Your task is to build, train, and evaluate an ANN model.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "### **Dataset:**\n",
    "* Just run the command under the `Load Data` section to get the data downloaded and unzipped or you can access it [here](https://drive.google.com/file/d/1Flvj3qDkV2rPw7GGi5zOR-WGJgEBtRk-/view?usp=sharing)\n",
    "\n",
    "### **Dataset Name:** Bus Breakdown and Delays\n",
    "\n",
    "### **Description:**  \n",
    "The dataset contains records of incidents involving buses that were either running late or experienced a breakdown. Your task is to predict whether the bus was delayed or had a breakdown based on the features provided.\n",
    "\n",
    "### **Features:**\n",
    "The dataset contains the following columns:\n",
    "\n",
    "- `School_Year`\n",
    "- `Busbreakdown_ID`\n",
    "- `Run_Type`\n",
    "- `Bus_No`\n",
    "- `Route_Number`\n",
    "- `Reason`\n",
    "- `Schools_Serviced`\n",
    "- `Occurred_On`\n",
    "- `Created_On`\n",
    "- `Boro`\n",
    "- `Bus_Company_Name`\n",
    "- `How_Long_Delayed`\n",
    "- `Number_Of_Students_On_The_Bus`\n",
    "- `Has_Contractor_Notified_Schools`\n",
    "- `Has_Contractor_Notified_Parents`\n",
    "- `Have_You_Alerted_OPT`\n",
    "- `Informed_On`\n",
    "- `Incident_Number`\n",
    "- `Last_Updated_On`\n",
    "- `Breakdown_or_Running_Late` (Target Column)\n",
    "- `School_Age_or_PreK`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b014b",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98ad02f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' #https://drive.google.com/file/d/1Flvj3qDkV2rPw7GGi5zOR-WGJgEBtRk-/view?usp=sharing\\n!pip install gdown\\n!gdown --id 1Flvj3qDkV2rPw7GGi5zOR-WGJgEBtRk-\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' #https://drive.google.com/file/d/1Flvj3qDkV2rPw7GGi5zOR-WGJgEBtRk-/view?usp=sharing\n",
    "!pip install gdown\n",
    "!gdown --id 1Flvj3qDkV2rPw7GGi5zOR-WGJgEBtRk-\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e39620c",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62381953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eadcb660",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Bus_Breakdown_and_Delays.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bacb0c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>School_Year</th>\n",
       "      <th>Busbreakdown_ID</th>\n",
       "      <th>Run_Type</th>\n",
       "      <th>Bus_No</th>\n",
       "      <th>Route_Number</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Schools_Serviced</th>\n",
       "      <th>Occurred_On</th>\n",
       "      <th>Created_On</th>\n",
       "      <th>Boro</th>\n",
       "      <th>...</th>\n",
       "      <th>How_Long_Delayed</th>\n",
       "      <th>Number_Of_Students_On_The_Bus</th>\n",
       "      <th>Has_Contractor_Notified_Schools</th>\n",
       "      <th>Has_Contractor_Notified_Parents</th>\n",
       "      <th>Have_You_Alerted_OPT</th>\n",
       "      <th>Informed_On</th>\n",
       "      <th>Incident_Number</th>\n",
       "      <th>Last_Updated_On</th>\n",
       "      <th>Breakdown_or_Running_Late</th>\n",
       "      <th>School_Age_or_PreK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-2016</td>\n",
       "      <td>1224901</td>\n",
       "      <td>Pre-K/EI</td>\n",
       "      <td>811</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>C353</td>\n",
       "      <td>10/26/2015 08:30:00 AM</td>\n",
       "      <td>10/26/2015 08:40:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>...</td>\n",
       "      <td>10MINUTES</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>10/26/2015 08:40:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/26/2015 08:40:39 AM</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-2016</td>\n",
       "      <td>1225098</td>\n",
       "      <td>Pre-K/EI</td>\n",
       "      <td>9302</td>\n",
       "      <td>1</td>\n",
       "      <td>Heavy Traffic</td>\n",
       "      <td>C814</td>\n",
       "      <td>10/27/2015 07:10:00 AM</td>\n",
       "      <td>10/27/2015 07:11:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>...</td>\n",
       "      <td>25 MINUTES</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>10/27/2015 07:11:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10/27/2015 07:11:22 AM</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-2016</td>\n",
       "      <td>1215800</td>\n",
       "      <td>Pre-K/EI</td>\n",
       "      <td>358</td>\n",
       "      <td>2</td>\n",
       "      <td>Heavy Traffic</td>\n",
       "      <td>C195</td>\n",
       "      <td>09/18/2015 07:36:00 AM</td>\n",
       "      <td>09/18/2015 07:38:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>...</td>\n",
       "      <td>15 MINUTES</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>09/18/2015 07:38:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/18/2015 07:38:44 AM</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-2016</td>\n",
       "      <td>1215511</td>\n",
       "      <td>Pre-K/EI</td>\n",
       "      <td>331</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>C178</td>\n",
       "      <td>09/17/2015 08:08:00 AM</td>\n",
       "      <td>09/17/2015 08:12:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>...</td>\n",
       "      <td>10 minutes</td>\n",
       "      <td>11</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>09/17/2015 08:12:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/17/2015 08:12:08 AM</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-2016</td>\n",
       "      <td>1215828</td>\n",
       "      <td>Pre-K/EI</td>\n",
       "      <td>332</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>S176</td>\n",
       "      <td>09/18/2015 07:39:00 AM</td>\n",
       "      <td>09/18/2015 07:45:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>...</td>\n",
       "      <td>10MINUTES</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>09/18/2015 07:45:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/18/2015 07:56:40 AM</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  School_Year  Busbreakdown_ID  Run_Type Bus_No Route_Number         Reason  \\\n",
       "0   2015-2016          1224901  Pre-K/EI    811            1          Other   \n",
       "1   2015-2016          1225098  Pre-K/EI   9302            1  Heavy Traffic   \n",
       "2   2015-2016          1215800  Pre-K/EI    358            2  Heavy Traffic   \n",
       "3   2015-2016          1215511  Pre-K/EI    331            2          Other   \n",
       "4   2015-2016          1215828  Pre-K/EI    332            2          Other   \n",
       "\n",
       "  Schools_Serviced             Occurred_On              Created_On   Boro  \\\n",
       "0             C353  10/26/2015 08:30:00 AM  10/26/2015 08:40:00 AM  Bronx   \n",
       "1             C814  10/27/2015 07:10:00 AM  10/27/2015 07:11:00 AM  Bronx   \n",
       "2             C195  09/18/2015 07:36:00 AM  09/18/2015 07:38:00 AM  Bronx   \n",
       "3             C178  09/17/2015 08:08:00 AM  09/17/2015 08:12:00 AM  Bronx   \n",
       "4             S176  09/18/2015 07:39:00 AM  09/18/2015 07:45:00 AM  Bronx   \n",
       "\n",
       "   ... How_Long_Delayed Number_Of_Students_On_The_Bus  \\\n",
       "0  ...        10MINUTES                             5   \n",
       "1  ...       25 MINUTES                             3   \n",
       "2  ...       15 MINUTES                            12   \n",
       "3  ...       10 minutes                            11   \n",
       "4  ...        10MINUTES                            12   \n",
       "\n",
       "   Has_Contractor_Notified_Schools Has_Contractor_Notified_Parents  \\\n",
       "0                              Yes                             Yes   \n",
       "1                              Yes                             Yes   \n",
       "2                              Yes                             Yes   \n",
       "3                              Yes                             Yes   \n",
       "4                              Yes                             Yes   \n",
       "\n",
       "  Have_You_Alerted_OPT             Informed_On Incident_Number  \\\n",
       "0                   No  10/26/2015 08:40:00 AM             NaN   \n",
       "1                   No  10/27/2015 07:11:00 AM             NaN   \n",
       "2                  Yes  09/18/2015 07:38:00 AM             NaN   \n",
       "3                  Yes  09/17/2015 08:12:00 AM             NaN   \n",
       "4                   No  09/18/2015 07:45:00 AM             NaN   \n",
       "\n",
       "          Last_Updated_On Breakdown_or_Running_Late School_Age_or_PreK  \n",
       "0  10/26/2015 08:40:39 AM              Running Late              Pre-K  \n",
       "1  10/27/2015 07:11:22 AM              Running Late              Pre-K  \n",
       "2  09/18/2015 07:38:44 AM              Running Late              Pre-K  \n",
       "3  09/17/2015 08:12:08 AM              Running Late              Pre-K  \n",
       "4  09/18/2015 07:56:40 AM              Running Late              Pre-K  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be0ca124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['School_Year', 'Busbreakdown_ID', 'Run_Type', 'Bus_No', 'Route_Number',\n",
       "       'Reason', 'Schools_Serviced', 'Occurred_On', 'Created_On', 'Boro',\n",
       "       'Bus_Company_Name', 'How_Long_Delayed', 'Number_Of_Students_On_The_Bus',\n",
       "       'Has_Contractor_Notified_Schools', 'Has_Contractor_Notified_Parents',\n",
       "       'Have_You_Alerted_OPT', 'Informed_On', 'Incident_Number',\n",
       "       'Last_Updated_On', 'Breakdown_or_Running_Late', 'School_Age_or_PreK'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd717c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'categorical_cols = df.select_dtypes(include=[\\'object\\',\\'category\\']).columns\\n\\nfor col in categorical_cols:\\n    print(df[col].value_counts())\\n    print(\"\\n\")'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''categorical_cols = df.select_dtypes(include=['object','category']).columns\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(df[col].value_counts())\n",
    "    print(\"\\n\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ccd4e2",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "This could include:\n",
    "* **Inspect the dataset**\n",
    "\n",
    "* **Dataset structure**\n",
    "\n",
    "* **Summary statistics**\n",
    "\n",
    "* **Check for missing values**\n",
    "\n",
    "* **Distribution of features**\n",
    "\n",
    "* **Categorical feature analysis**\n",
    "\n",
    "* **Correlation matrix**\n",
    "\n",
    "* **Outlier detection**\n",
    "\n",
    "And add more as needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b800b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147972, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73c6fa78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Busbreakdown_ID</th>\n",
       "      <th>Number_Of_Students_On_The_Bus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.479720e+05</td>\n",
       "      <td>147972.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.287779e+06</td>\n",
       "      <td>3.590071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.324338e+04</td>\n",
       "      <td>55.365859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.212681e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.250438e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.287844e+06</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.325191e+06</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.362605e+06</td>\n",
       "      <td>9007.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Busbreakdown_ID  Number_Of_Students_On_The_Bus\n",
       "count     1.479720e+05                  147972.000000\n",
       "mean      1.287779e+06                       3.590071\n",
       "std       4.324338e+04                      55.365859\n",
       "min       1.212681e+06                       0.000000\n",
       "25%       1.250438e+06                       0.000000\n",
       "50%       1.287844e+06                       0.000000\n",
       "75%       1.325191e+06                       4.000000\n",
       "max       1.362605e+06                    9007.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "School_Year                             0\n",
       "Busbreakdown_ID                         0\n",
       "Run_Type                               89\n",
       "Bus_No                                  0\n",
       "Route_Number                           88\n",
       "Reason                                102\n",
       "Schools_Serviced                        0\n",
       "Occurred_On                             0\n",
       "Created_On                              0\n",
       "Boro                                 6318\n",
       "Bus_Company_Name                        0\n",
       "How_Long_Delayed                    21630\n",
       "Number_Of_Students_On_The_Bus           0\n",
       "Has_Contractor_Notified_Schools         0\n",
       "Has_Contractor_Notified_Parents         0\n",
       "Have_You_Alerted_OPT                    0\n",
       "Informed_On                             0\n",
       "Incident_Number                    142340\n",
       "Last_Updated_On                         0\n",
       "Breakdown_or_Running_Late               0\n",
       "School_Age_or_PreK                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b793e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "School_Year                        object\n",
       "Busbreakdown_ID                     int64\n",
       "Run_Type                           object\n",
       "Bus_No                             object\n",
       "Route_Number                       object\n",
       "Reason                             object\n",
       "Schools_Serviced                   object\n",
       "Occurred_On                        object\n",
       "Created_On                         object\n",
       "Boro                               object\n",
       "Bus_Company_Name                   object\n",
       "How_Long_Delayed                   object\n",
       "Number_Of_Students_On_The_Bus       int64\n",
       "Has_Contractor_Notified_Schools    object\n",
       "Has_Contractor_Notified_Parents    object\n",
       "Have_You_Alerted_OPT               object\n",
       "Informed_On                        object\n",
       "Incident_Number                    object\n",
       "Last_Updated_On                    object\n",
       "Breakdown_or_Running_Late          object\n",
       "School_Age_or_PreK                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1c696ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>School_Year</th>\n",
       "      <th>Busbreakdown_ID</th>\n",
       "      <th>Run_Type</th>\n",
       "      <th>Bus_No</th>\n",
       "      <th>Route_Number</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Schools_Serviced</th>\n",
       "      <th>Occurred_On</th>\n",
       "      <th>Created_On</th>\n",
       "      <th>Boro</th>\n",
       "      <th>...</th>\n",
       "      <th>How_Long_Delayed</th>\n",
       "      <th>Number_Of_Students_On_The_Bus</th>\n",
       "      <th>Has_Contractor_Notified_Schools</th>\n",
       "      <th>Has_Contractor_Notified_Parents</th>\n",
       "      <th>Have_You_Alerted_OPT</th>\n",
       "      <th>Informed_On</th>\n",
       "      <th>Incident_Number</th>\n",
       "      <th>Last_Updated_On</th>\n",
       "      <th>Breakdown_or_Running_Late</th>\n",
       "      <th>School_Age_or_PreK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119246</th>\n",
       "      <td>2016-2017</td>\n",
       "      <td>1340461</td>\n",
       "      <td>Special Ed AM Run</td>\n",
       "      <td>5409</td>\n",
       "      <td>L926</td>\n",
       "      <td>Heavy Traffic</td>\n",
       "      <td>17138</td>\n",
       "      <td>04/20/2017 07:41:00 AM</td>\n",
       "      <td>04/20/2017 07:42:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20 MIN</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>04/20/2017 07:42:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/20/2017 07:42:09 AM</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>School-Age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129578</th>\n",
       "      <td>2016-2017</td>\n",
       "      <td>1351173</td>\n",
       "      <td>Special Ed AM Run</td>\n",
       "      <td>1367</td>\n",
       "      <td>M352</td>\n",
       "      <td>Heavy Traffic</td>\n",
       "      <td>02533</td>\n",
       "      <td>05/22/2017 07:06:00 AM</td>\n",
       "      <td>05/22/2017 07:06:00 AM</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>...</td>\n",
       "      <td>20MNTS</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>05/22/2017 07:06:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>05/22/2017 07:06:45 AM</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>School-Age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67599</th>\n",
       "      <td>2016-2017</td>\n",
       "      <td>1288368</td>\n",
       "      <td>Special Ed AM Run</td>\n",
       "      <td>NI0932</td>\n",
       "      <td>K118</td>\n",
       "      <td>Heavy Traffic</td>\n",
       "      <td>75907</td>\n",
       "      <td>09/27/2016 07:00:00 AM</td>\n",
       "      <td>09/27/2016 07:11:00 AM</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>...</td>\n",
       "      <td>20 min</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>09/27/2016 07:11:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>09/27/2016 09:46:31 AM</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>School-Age</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116053</th>\n",
       "      <td>2016-2017</td>\n",
       "      <td>1337283</td>\n",
       "      <td>Pre-K/EI</td>\n",
       "      <td>9345</td>\n",
       "      <td>2</td>\n",
       "      <td>Heavy Traffic</td>\n",
       "      <td>C530</td>\n",
       "      <td>04/03/2017 08:01:00 AM</td>\n",
       "      <td>04/03/2017 08:04:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>...</td>\n",
       "      <td>20 MINS</td>\n",
       "      <td>6</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>04/03/2017 08:04:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04/03/2017 08:04:14 AM</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80539</th>\n",
       "      <td>2016-2017</td>\n",
       "      <td>1301328</td>\n",
       "      <td>Special Ed AM Run</td>\n",
       "      <td>1333</td>\n",
       "      <td>Q192</td>\n",
       "      <td>Flat Tire</td>\n",
       "      <td>30234</td>\n",
       "      <td>11/21/2016 06:26:00 AM</td>\n",
       "      <td>11/21/2016 06:29:00 AM</td>\n",
       "      <td>Queens</td>\n",
       "      <td>...</td>\n",
       "      <td>1 Hour</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>11/21/2016 06:29:00 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11/21/2016 09:00:20 AM</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>School-Age</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       School_Year  Busbreakdown_ID           Run_Type  Bus_No Route_Number  \\\n",
       "119246   2016-2017          1340461  Special Ed AM Run    5409         L926   \n",
       "129578   2016-2017          1351173  Special Ed AM Run    1367         M352   \n",
       "67599    2016-2017          1288368  Special Ed AM Run  NI0932         K118   \n",
       "116053   2016-2017          1337283           Pre-K/EI    9345            2   \n",
       "80539    2016-2017          1301328  Special Ed AM Run    1333         Q192   \n",
       "\n",
       "               Reason Schools_Serviced             Occurred_On  \\\n",
       "119246  Heavy Traffic            17138  04/20/2017 07:41:00 AM   \n",
       "129578  Heavy Traffic            02533  05/22/2017 07:06:00 AM   \n",
       "67599   Heavy Traffic            75907  09/27/2016 07:00:00 AM   \n",
       "116053  Heavy Traffic             C530  04/03/2017 08:01:00 AM   \n",
       "80539       Flat Tire            30234  11/21/2016 06:26:00 AM   \n",
       "\n",
       "                    Created_On       Boro  ... How_Long_Delayed  \\\n",
       "119246  04/20/2017 07:42:00 AM        NaN  ...           20 MIN   \n",
       "129578  05/22/2017 07:06:00 AM  Manhattan  ...           20MNTS   \n",
       "67599   09/27/2016 07:11:00 AM   Brooklyn  ...           20 min   \n",
       "116053  04/03/2017 08:04:00 AM      Bronx  ...          20 MINS   \n",
       "80539   11/21/2016 06:29:00 AM     Queens  ...           1 Hour   \n",
       "\n",
       "       Number_Of_Students_On_The_Bus  Has_Contractor_Notified_Schools  \\\n",
       "119246                             2                              Yes   \n",
       "129578                             0                              Yes   \n",
       "67599                              0                              Yes   \n",
       "116053                             6                              Yes   \n",
       "80539                              0                              Yes   \n",
       "\n",
       "       Has_Contractor_Notified_Parents Have_You_Alerted_OPT  \\\n",
       "119246                             Yes                  Yes   \n",
       "129578                             Yes                   No   \n",
       "67599                              Yes                   No   \n",
       "116053                             Yes                   No   \n",
       "80539                              Yes                  Yes   \n",
       "\n",
       "                   Informed_On Incident_Number         Last_Updated_On  \\\n",
       "119246  04/20/2017 07:42:00 AM             NaN  04/20/2017 07:42:09 AM   \n",
       "129578  05/22/2017 07:06:00 AM             NaN  05/22/2017 07:06:45 AM   \n",
       "67599   09/27/2016 07:11:00 AM             NaN  09/27/2016 09:46:31 AM   \n",
       "116053  04/03/2017 08:04:00 AM             NaN  04/03/2017 08:04:14 AM   \n",
       "80539   11/21/2016 06:29:00 AM             NaN  11/21/2016 09:00:20 AM   \n",
       "\n",
       "       Breakdown_or_Running_Late School_Age_or_PreK  \n",
       "119246              Running Late         School-Age  \n",
       "129578              Running Late         School-Age  \n",
       "67599               Running Late         School-Age  \n",
       "116053              Running Late              Pre-K  \n",
       "80539               Running Late         School-Age  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14c198ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_numerical_cols = ['Number_Of_Students_On_The_Bus']\n",
    "conv_categorical_cols = ['School_Year','Busbreakdown_ID','Run_Type','Bus_No','Route_Number','Reason','Breakdown_or_Running_Late','School_Age_or_PreK'\n",
    "                         'Boro','Bus_Company_Name','How_Long_Delayed','Number_Of_Students_On_The_Bus','Has_Contractor_Notified_Schools','Has_Contractor_Notified_Parents','Have_You_Alerted_OPT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fc0402a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "sns.boxplot(x=df['Number_Of_Students_On_The_Bus'])\n",
    "plt.title('Box plot of Number_Of_Students_On_The_Bus')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e98009a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a559e40",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "This could include:\n",
    "\n",
    "* **Handle Missing Values**\n",
    "    * Impute missing values or drop them.\n",
    "\n",
    "* **Encode Categorical Variables**\n",
    "    * One-hot encoding\n",
    "    * Label encoding\n",
    "\n",
    "* **Scale and Normalize Data**\n",
    "    * Standardization (Z-score)\n",
    "    * Min-Max scaling\n",
    "\n",
    "* **Feature Engineering**\n",
    "    * Create new features\n",
    "    * Feature selection\n",
    "\n",
    "* **Handle Imbalanced Data**\n",
    "    * Oversampling\n",
    "    * Undersampling\n",
    "\n",
    "* **Handle Outliers**\n",
    "    * Remove outliers\n",
    "    * Transform outliers\n",
    "\n",
    "* **Remove Duplicates**\n",
    "    * Remove redundant or duplicate data\n",
    "\n",
    "\n",
    "And add more as needed!\n",
    "\n",
    "Please treat these as suggestions. Feel free to use your judgment for the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66e68947",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['School_Age_or_PreK','Breakdown_or_Running_Late','Have_You_Alerted_OPT','Has_Contractor_Notified_Parents','Has_Contractor_Notified_Schools','Boro','Bus_Company_Name',\n",
    "     'Schools_Serviced','Reason','Bus_No','Run_Type','Busbreakdown_ID','School_Year']] = df[['School_Age_or_PreK','Breakdown_or_Running_Late','Have_You_Alerted_OPT','Has_Contractor_Notified_Parents','Has_Contractor_Notified_Schools','Boro','Bus_Company_Name',\n",
    "     'Schools_Serviced','Reason','Bus_No','Run_Type','Busbreakdown_ID','School_Year']].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7060ea69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "School_Year                        object\n",
       "Busbreakdown_ID                    object\n",
       "Run_Type                           object\n",
       "Bus_No                             object\n",
       "Route_Number                       object\n",
       "Reason                             object\n",
       "Schools_Serviced                   object\n",
       "Occurred_On                        object\n",
       "Created_On                         object\n",
       "Boro                               object\n",
       "Bus_Company_Name                   object\n",
       "How_Long_Delayed                   object\n",
       "Number_Of_Students_On_The_Bus       int64\n",
       "Has_Contractor_Notified_Schools    object\n",
       "Has_Contractor_Notified_Parents    object\n",
       "Have_You_Alerted_OPT               object\n",
       "Informed_On                        object\n",
       "Incident_Number                    object\n",
       "Last_Updated_On                    object\n",
       "Breakdown_or_Running_Late          object\n",
       "School_Age_or_PreK                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95675c46",
   "metadata": {},
   "source": [
    "Deal with nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24d38937",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Incident_Number','How_Long_Delayed','Informed_On','Last_Updated_On','School_Year','Run_Type'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa8a7221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Busbreakdown_ID</th>\n",
       "      <th>Bus_No</th>\n",
       "      <th>Route_Number</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Schools_Serviced</th>\n",
       "      <th>Occurred_On</th>\n",
       "      <th>Created_On</th>\n",
       "      <th>Boro</th>\n",
       "      <th>Bus_Company_Name</th>\n",
       "      <th>Number_Of_Students_On_The_Bus</th>\n",
       "      <th>Has_Contractor_Notified_Schools</th>\n",
       "      <th>Has_Contractor_Notified_Parents</th>\n",
       "      <th>Have_You_Alerted_OPT</th>\n",
       "      <th>Breakdown_or_Running_Late</th>\n",
       "      <th>School_Age_or_PreK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1224901</td>\n",
       "      <td>811</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>C353</td>\n",
       "      <td>10/26/2015 08:30:00 AM</td>\n",
       "      <td>10/26/2015 08:40:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>G.V.C., LTD.</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1225098</td>\n",
       "      <td>9302</td>\n",
       "      <td>1</td>\n",
       "      <td>Heavy Traffic</td>\n",
       "      <td>C814</td>\n",
       "      <td>10/27/2015 07:10:00 AM</td>\n",
       "      <td>10/27/2015 07:11:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>G.V.C., LTD.</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1215800</td>\n",
       "      <td>358</td>\n",
       "      <td>2</td>\n",
       "      <td>Heavy Traffic</td>\n",
       "      <td>C195</td>\n",
       "      <td>09/18/2015 07:36:00 AM</td>\n",
       "      <td>09/18/2015 07:38:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>G.V.C., LTD.</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1215511</td>\n",
       "      <td>331</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>C178</td>\n",
       "      <td>09/17/2015 08:08:00 AM</td>\n",
       "      <td>09/17/2015 08:12:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>G.V.C., LTD.</td>\n",
       "      <td>11</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1215828</td>\n",
       "      <td>332</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>S176</td>\n",
       "      <td>09/18/2015 07:39:00 AM</td>\n",
       "      <td>09/18/2015 07:45:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>G.V.C., LTD.</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Busbreakdown_ID Bus_No Route_Number         Reason Schools_Serviced  \\\n",
       "0         1224901    811            1          Other             C353   \n",
       "1         1225098   9302            1  Heavy Traffic             C814   \n",
       "2         1215800    358            2  Heavy Traffic             C195   \n",
       "3         1215511    331            2          Other             C178   \n",
       "4         1215828    332            2          Other             S176   \n",
       "\n",
       "              Occurred_On              Created_On   Boro Bus_Company_Name  \\\n",
       "0  10/26/2015 08:30:00 AM  10/26/2015 08:40:00 AM  Bronx     G.V.C., LTD.   \n",
       "1  10/27/2015 07:10:00 AM  10/27/2015 07:11:00 AM  Bronx     G.V.C., LTD.   \n",
       "2  09/18/2015 07:36:00 AM  09/18/2015 07:38:00 AM  Bronx     G.V.C., LTD.   \n",
       "3  09/17/2015 08:08:00 AM  09/17/2015 08:12:00 AM  Bronx     G.V.C., LTD.   \n",
       "4  09/18/2015 07:39:00 AM  09/18/2015 07:45:00 AM  Bronx     G.V.C., LTD.   \n",
       "\n",
       "   Number_Of_Students_On_The_Bus Has_Contractor_Notified_Schools  \\\n",
       "0                              5                             Yes   \n",
       "1                              3                             Yes   \n",
       "2                             12                             Yes   \n",
       "3                             11                             Yes   \n",
       "4                             12                             Yes   \n",
       "\n",
       "  Has_Contractor_Notified_Parents Have_You_Alerted_OPT  \\\n",
       "0                             Yes                   No   \n",
       "1                             Yes                   No   \n",
       "2                             Yes                  Yes   \n",
       "3                             Yes                  Yes   \n",
       "4                             Yes                   No   \n",
       "\n",
       "  Breakdown_or_Running_Late School_Age_or_PreK  \n",
       "0              Running Late              Pre-K  \n",
       "1              Running Late              Pre-K  \n",
       "2              Running Late              Pre-K  \n",
       "3              Running Late              Pre-K  \n",
       "4              Running Late              Pre-K  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88533838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Bronx\n",
       "Name: Boro, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Boro'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eeed17de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Boro'].fillna('Bronx',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "126212b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Run_Type'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62b946b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['Run_Type'].fillna('Special Ed AM Run',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43624b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "Name: Route_Number, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Route_Number'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fadb492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Route_Number'].fillna('1',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8c313db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Heavy Traffic\n",
       "Name: Reason, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Reason'].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "554d4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Reason'].fillna('Heavy Traffic',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8532a6a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Busbreakdown_ID                    0\n",
       "Bus_No                             0\n",
       "Route_Number                       0\n",
       "Reason                             0\n",
       "Schools_Serviced                   0\n",
       "Occurred_On                        0\n",
       "Created_On                         0\n",
       "Boro                               0\n",
       "Bus_Company_Name                   0\n",
       "Number_Of_Students_On_The_Bus      0\n",
       "Has_Contractor_Notified_Schools    0\n",
       "Has_Contractor_Notified_Parents    0\n",
       "Have_You_Alerted_OPT               0\n",
       "Breakdown_or_Running_Late          0\n",
       "School_Age_or_PreK                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f836c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6ccfda",
   "metadata": {},
   "source": [
    "Encoder:  \n",
    "for category will make OneHotEncoder  \n",
    "for numrical will make StanderScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d07a474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Busbreakdown_ID</th>\n",
       "      <th>Bus_No</th>\n",
       "      <th>Route_Number</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Schools_Serviced</th>\n",
       "      <th>Occurred_On</th>\n",
       "      <th>Created_On</th>\n",
       "      <th>Boro</th>\n",
       "      <th>Bus_Company_Name</th>\n",
       "      <th>Number_Of_Students_On_The_Bus</th>\n",
       "      <th>Has_Contractor_Notified_Schools</th>\n",
       "      <th>Has_Contractor_Notified_Parents</th>\n",
       "      <th>Have_You_Alerted_OPT</th>\n",
       "      <th>Breakdown_or_Running_Late</th>\n",
       "      <th>School_Age_or_PreK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1224901</td>\n",
       "      <td>811</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>C353</td>\n",
       "      <td>10/26/2015 08:30:00 AM</td>\n",
       "      <td>10/26/2015 08:40:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>G.V.C., LTD.</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1225098</td>\n",
       "      <td>9302</td>\n",
       "      <td>1</td>\n",
       "      <td>Heavy Traffic</td>\n",
       "      <td>C814</td>\n",
       "      <td>10/27/2015 07:10:00 AM</td>\n",
       "      <td>10/27/2015 07:11:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>G.V.C., LTD.</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1215800</td>\n",
       "      <td>358</td>\n",
       "      <td>2</td>\n",
       "      <td>Heavy Traffic</td>\n",
       "      <td>C195</td>\n",
       "      <td>09/18/2015 07:36:00 AM</td>\n",
       "      <td>09/18/2015 07:38:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>G.V.C., LTD.</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1215511</td>\n",
       "      <td>331</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>C178</td>\n",
       "      <td>09/17/2015 08:08:00 AM</td>\n",
       "      <td>09/17/2015 08:12:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>G.V.C., LTD.</td>\n",
       "      <td>11</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1215828</td>\n",
       "      <td>332</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>S176</td>\n",
       "      <td>09/18/2015 07:39:00 AM</td>\n",
       "      <td>09/18/2015 07:45:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>G.V.C., LTD.</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Busbreakdown_ID Bus_No Route_Number         Reason Schools_Serviced  \\\n",
       "0         1224901    811            1          Other             C353   \n",
       "1         1225098   9302            1  Heavy Traffic             C814   \n",
       "2         1215800    358            2  Heavy Traffic             C195   \n",
       "3         1215511    331            2          Other             C178   \n",
       "4         1215828    332            2          Other             S176   \n",
       "\n",
       "              Occurred_On              Created_On   Boro Bus_Company_Name  \\\n",
       "0  10/26/2015 08:30:00 AM  10/26/2015 08:40:00 AM  Bronx     G.V.C., LTD.   \n",
       "1  10/27/2015 07:10:00 AM  10/27/2015 07:11:00 AM  Bronx     G.V.C., LTD.   \n",
       "2  09/18/2015 07:36:00 AM  09/18/2015 07:38:00 AM  Bronx     G.V.C., LTD.   \n",
       "3  09/17/2015 08:08:00 AM  09/17/2015 08:12:00 AM  Bronx     G.V.C., LTD.   \n",
       "4  09/18/2015 07:39:00 AM  09/18/2015 07:45:00 AM  Bronx     G.V.C., LTD.   \n",
       "\n",
       "   Number_Of_Students_On_The_Bus Has_Contractor_Notified_Schools  \\\n",
       "0                              5                             Yes   \n",
       "1                              3                             Yes   \n",
       "2                             12                             Yes   \n",
       "3                             11                             Yes   \n",
       "4                             12                             Yes   \n",
       "\n",
       "  Has_Contractor_Notified_Parents Have_You_Alerted_OPT  \\\n",
       "0                             Yes                   No   \n",
       "1                             Yes                   No   \n",
       "2                             Yes                  Yes   \n",
       "3                             Yes                  Yes   \n",
       "4                             Yes                   No   \n",
       "\n",
       "  Breakdown_or_Running_Late School_Age_or_PreK  \n",
       "0              Running Late              Pre-K  \n",
       "1              Running Late              Pre-K  \n",
       "2              Running Late              Pre-K  \n",
       "3              Running Late              Pre-K  \n",
       "4              Running Late              Pre-K  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41feed83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Busbreakdown_ID                    object\n",
       "Bus_No                             object\n",
       "Route_Number                       object\n",
       "Reason                             object\n",
       "Schools_Serviced                   object\n",
       "Occurred_On                        object\n",
       "Created_On                         object\n",
       "Boro                               object\n",
       "Bus_Company_Name                   object\n",
       "Number_Of_Students_On_The_Bus       int64\n",
       "Has_Contractor_Notified_Schools    object\n",
       "Has_Contractor_Notified_Parents    object\n",
       "Have_You_Alerted_OPT               object\n",
       "Breakdown_or_Running_Late          object\n",
       "School_Age_or_PreK                 object\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ca14346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Busbreakdown_ID</th>\n",
       "      <th>Bus_No</th>\n",
       "      <th>Route_Number</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Schools_Serviced</th>\n",
       "      <th>Occurred_On</th>\n",
       "      <th>Created_On</th>\n",
       "      <th>Boro</th>\n",
       "      <th>Bus_Company_Name</th>\n",
       "      <th>Number_Of_Students_On_The_Bus</th>\n",
       "      <th>Has_Contractor_Notified_Schools</th>\n",
       "      <th>Has_Contractor_Notified_Parents</th>\n",
       "      <th>Have_You_Alerted_OPT</th>\n",
       "      <th>Breakdown_or_Running_Late</th>\n",
       "      <th>School_Age_or_PreK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1224901</td>\n",
       "      <td>811</td>\n",
       "      <td>1</td>\n",
       "      <td>Other</td>\n",
       "      <td>C353</td>\n",
       "      <td>10/26/2015 08:30:00 AM</td>\n",
       "      <td>10/26/2015 08:40:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>G.V.C., LTD.</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1225098</td>\n",
       "      <td>9302</td>\n",
       "      <td>1</td>\n",
       "      <td>Heavy Traffic</td>\n",
       "      <td>C814</td>\n",
       "      <td>10/27/2015 07:10:00 AM</td>\n",
       "      <td>10/27/2015 07:11:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>G.V.C., LTD.</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1215800</td>\n",
       "      <td>358</td>\n",
       "      <td>2</td>\n",
       "      <td>Heavy Traffic</td>\n",
       "      <td>C195</td>\n",
       "      <td>09/18/2015 07:36:00 AM</td>\n",
       "      <td>09/18/2015 07:38:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>G.V.C., LTD.</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1215511</td>\n",
       "      <td>331</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>C178</td>\n",
       "      <td>09/17/2015 08:08:00 AM</td>\n",
       "      <td>09/17/2015 08:12:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>G.V.C., LTD.</td>\n",
       "      <td>11</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1215828</td>\n",
       "      <td>332</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>S176</td>\n",
       "      <td>09/18/2015 07:39:00 AM</td>\n",
       "      <td>09/18/2015 07:45:00 AM</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>G.V.C., LTD.</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Running Late</td>\n",
       "      <td>Pre-K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Busbreakdown_ID Bus_No Route_Number         Reason Schools_Serviced  \\\n",
       "0         1224901    811            1          Other             C353   \n",
       "1         1225098   9302            1  Heavy Traffic             C814   \n",
       "2         1215800    358            2  Heavy Traffic             C195   \n",
       "3         1215511    331            2          Other             C178   \n",
       "4         1215828    332            2          Other             S176   \n",
       "\n",
       "              Occurred_On              Created_On   Boro Bus_Company_Name  \\\n",
       "0  10/26/2015 08:30:00 AM  10/26/2015 08:40:00 AM  Bronx     G.V.C., LTD.   \n",
       "1  10/27/2015 07:10:00 AM  10/27/2015 07:11:00 AM  Bronx     G.V.C., LTD.   \n",
       "2  09/18/2015 07:36:00 AM  09/18/2015 07:38:00 AM  Bronx     G.V.C., LTD.   \n",
       "3  09/17/2015 08:08:00 AM  09/17/2015 08:12:00 AM  Bronx     G.V.C., LTD.   \n",
       "4  09/18/2015 07:39:00 AM  09/18/2015 07:45:00 AM  Bronx     G.V.C., LTD.   \n",
       "\n",
       "   Number_Of_Students_On_The_Bus Has_Contractor_Notified_Schools  \\\n",
       "0                              5                             Yes   \n",
       "1                              3                             Yes   \n",
       "2                             12                             Yes   \n",
       "3                             11                             Yes   \n",
       "4                             12                             Yes   \n",
       "\n",
       "  Has_Contractor_Notified_Parents Have_You_Alerted_OPT  \\\n",
       "0                             Yes                   No   \n",
       "1                             Yes                   No   \n",
       "2                             Yes                  Yes   \n",
       "3                             Yes                  Yes   \n",
       "4                             Yes                   No   \n",
       "\n",
       "  Breakdown_or_Running_Late School_Age_or_PreK  \n",
       "0              Running Late              Pre-K  \n",
       "1              Running Late              Pre-K  \n",
       "2              Running Late              Pre-K  \n",
       "3              Running Late              Pre-K  \n",
       "4              Running Late              Pre-K  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6867a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "le = OrdinalEncoder()\n",
    "\n",
    "'''df[['School_Age_or_PreK','Breakdown_or_Running_Late','Have_You_Alerted_OPT','Has_Contractor_Notified_Parents','Has_Contractor_Notified_Schools','Boro','Bus_Company_Name',\n",
    "     'Schools_Serviced','Reason','Bus_No','Run_Type','Busbreakdown_ID']]=le.fit_transform(df[['School_Age_or_PreK','Breakdown_or_Running_Late','Have_You_Alerted_OPT','Has_Contractor_Notified_Parents','Has_Contractor_Notified_Schools','Boro','Bus_Company_Name',\n",
    "     'Schools_Serviced','Reason','Bus_No','Run_Type','Busbreakdown_ID']])'''\n",
    "\n",
    "df[categorical_cols] = le.fit_transform(df[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e85d60c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "d:\\anaconda\\Lib\\site-packages\\sklearn\\utils\\validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f693fb6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc887660",
   "metadata": {},
   "source": [
    "## Split the Dataset\n",
    "Next, split the dataset into training, validation, and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0ecdd13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Busbreakdown_ID</th>\n",
       "      <th>Bus_No</th>\n",
       "      <th>Route_Number</th>\n",
       "      <th>Reason</th>\n",
       "      <th>Schools_Serviced</th>\n",
       "      <th>Occurred_On</th>\n",
       "      <th>Created_On</th>\n",
       "      <th>Boro</th>\n",
       "      <th>Bus_Company_Name</th>\n",
       "      <th>Number_Of_Students_On_The_Bus</th>\n",
       "      <th>Has_Contractor_Notified_Schools</th>\n",
       "      <th>Has_Contractor_Notified_Parents</th>\n",
       "      <th>Have_You_Alerted_OPT</th>\n",
       "      <th>Breakdown_or_Running_Late</th>\n",
       "      <th>School_Age_or_PreK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.450668</td>\n",
       "      <td>0.917316</td>\n",
       "      <td>-1.468186</td>\n",
       "      <td>1.023572</td>\n",
       "      <td>1.321218</td>\n",
       "      <td>1.050204</td>\n",
       "      <td>1.056915</td>\n",
       "      <td>-0.943508</td>\n",
       "      <td>-0.726645</td>\n",
       "      <td>0.025466</td>\n",
       "      <td>0.252141</td>\n",
       "      <td>0.555295</td>\n",
       "      <td>-0.678187</td>\n",
       "      <td>0.361651</td>\n",
       "      <td>-2.461037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.446080</td>\n",
       "      <td>1.127583</td>\n",
       "      <td>-1.468186</td>\n",
       "      <td>-0.579807</td>\n",
       "      <td>1.362969</td>\n",
       "      <td>1.064961</td>\n",
       "      <td>1.070848</td>\n",
       "      <td>-0.943508</td>\n",
       "      <td>-0.726645</td>\n",
       "      <td>-0.010658</td>\n",
       "      <td>0.252141</td>\n",
       "      <td>0.555295</td>\n",
       "      <td>-0.678187</td>\n",
       "      <td>0.361651</td>\n",
       "      <td>-2.461037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.659864</td>\n",
       "      <td>-0.019089</td>\n",
       "      <td>-1.429436</td>\n",
       "      <td>-0.579807</td>\n",
       "      <td>1.300343</td>\n",
       "      <td>0.655494</td>\n",
       "      <td>0.646600</td>\n",
       "      <td>-0.943508</td>\n",
       "      <td>-0.726645</td>\n",
       "      <td>0.151898</td>\n",
       "      <td>0.252141</td>\n",
       "      <td>0.555295</td>\n",
       "      <td>1.474519</td>\n",
       "      <td>0.361651</td>\n",
       "      <td>-2.461037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.666466</td>\n",
       "      <td>-0.057289</td>\n",
       "      <td>-1.429436</td>\n",
       "      <td>1.023572</td>\n",
       "      <td>1.299729</td>\n",
       "      <td>0.648598</td>\n",
       "      <td>0.638874</td>\n",
       "      <td>-0.943508</td>\n",
       "      <td>-0.726645</td>\n",
       "      <td>0.133836</td>\n",
       "      <td>0.252141</td>\n",
       "      <td>0.555295</td>\n",
       "      <td>1.474519</td>\n",
       "      <td>0.361651</td>\n",
       "      <td>-2.461037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.659209</td>\n",
       "      <td>-0.054964</td>\n",
       "      <td>-1.429436</td>\n",
       "      <td>1.023572</td>\n",
       "      <td>1.410860</td>\n",
       "      <td>0.655639</td>\n",
       "      <td>0.646912</td>\n",
       "      <td>-0.943508</td>\n",
       "      <td>-0.726645</td>\n",
       "      <td>0.151898</td>\n",
       "      <td>0.252141</td>\n",
       "      <td>0.555295</td>\n",
       "      <td>-0.678187</td>\n",
       "      <td>0.361651</td>\n",
       "      <td>-2.461037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Busbreakdown_ID    Bus_No  Route_Number    Reason  Schools_Serviced  \\\n",
       "0        -1.450668  0.917316     -1.468186  1.023572          1.321218   \n",
       "1        -1.446080  1.127583     -1.468186 -0.579807          1.362969   \n",
       "2        -1.659864 -0.019089     -1.429436 -0.579807          1.300343   \n",
       "3        -1.666466 -0.057289     -1.429436  1.023572          1.299729   \n",
       "4        -1.659209 -0.054964     -1.429436  1.023572          1.410860   \n",
       "\n",
       "   Occurred_On  Created_On      Boro  Bus_Company_Name  \\\n",
       "0     1.050204    1.056915 -0.943508         -0.726645   \n",
       "1     1.064961    1.070848 -0.943508         -0.726645   \n",
       "2     0.655494    0.646600 -0.943508         -0.726645   \n",
       "3     0.648598    0.638874 -0.943508         -0.726645   \n",
       "4     0.655639    0.646912 -0.943508         -0.726645   \n",
       "\n",
       "   Number_Of_Students_On_The_Bus  Has_Contractor_Notified_Schools  \\\n",
       "0                       0.025466                         0.252141   \n",
       "1                      -0.010658                         0.252141   \n",
       "2                       0.151898                         0.252141   \n",
       "3                       0.133836                         0.252141   \n",
       "4                       0.151898                         0.252141   \n",
       "\n",
       "   Has_Contractor_Notified_Parents  Have_You_Alerted_OPT  \\\n",
       "0                         0.555295             -0.678187   \n",
       "1                         0.555295             -0.678187   \n",
       "2                         0.555295              1.474519   \n",
       "3                         0.555295              1.474519   \n",
       "4                         0.555295             -0.678187   \n",
       "\n",
       "   Breakdown_or_Running_Late  School_Age_or_PreK  \n",
       "0                   0.361651           -2.461037  \n",
       "1                   0.361651           -2.461037  \n",
       "2                   0.361651           -2.461037  \n",
       "3                   0.361651           -2.461037  \n",
       "4                   0.361651           -2.461037  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa5bbfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(columns=['Breakdown_or_Running_Late'])\n",
    "y = df['Breakdown_or_Running_Late']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7119b7d7",
   "metadata": {},
   "source": [
    "## Building the ANN Model\n",
    "In this section, define the architecture of the ANN by specifying the number of layers, neurons, and activation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8532b3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5e52e1",
   "metadata": {},
   "source": [
    "## Compile the Model\n",
    "Compile the ANN model by defining the optimizer, loss function, and evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab363be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,993</span> (50.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m12,993\u001b[0m (50.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,993</span> (50.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,993\u001b[0m (50.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a72223",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "Train the ANN model using the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f88323e",
   "metadata": {},
   "source": [
    "more epoches and batshes will incraese accuracy, i dont have enough time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e43fedab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: -0.0772 - val_accuracy: 0.0000e+00 - val_loss: -15.3373\n",
      "Epoch 2/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -267.2543 - val_accuracy: 0.0000e+00 - val_loss: -5423.4761\n",
      "Epoch 3/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -32091.0820 - val_accuracy: 0.0000e+00 - val_loss: -346241.2188\n",
      "Epoch 4/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -1127626.7500 - val_accuracy: 0.0000e+00 - val_loss: -7218042.0000\n",
      "Epoch 5/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -16834456.0000 - val_accuracy: 0.0000e+00 - val_loss: -74979664.0000\n",
      "Epoch 6/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -142931488.0000 - val_accuracy: 0.0000e+00 - val_loss: -489504032.0000\n",
      "Epoch 7/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -841156544.0000 - val_accuracy: 0.0000e+00 - val_loss: -2296502784.0000\n",
      "Epoch 8/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -3664768000.0000 - val_accuracy: 0.0000e+00 - val_loss: -8540683776.0000\n",
      "Epoch 9/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -12577536000.0000 - val_accuracy: 0.0000e+00 - val_loss: -26657527808.0000\n",
      "Epoch 10/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -37519753216.0000 - val_accuracy: 0.0000e+00 - val_loss: -72288346112.0000\n",
      "Epoch 11/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -96914235392.0000 - val_accuracy: 0.0000e+00 - val_loss: -175292891136.0000\n",
      "Epoch 12/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -232909144064.0000 - val_accuracy: 0.0000e+00 - val_loss: -387870785536.0000\n",
      "Epoch 13/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -503577149440.0000 - val_accuracy: 0.0000e+00 - val_loss: -792069275648.0000\n",
      "Epoch 14/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -978112086016.0000 - val_accuracy: 0.0000e+00 - val_loss: -1520732209152.0000\n",
      "Epoch 15/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -1907104546816.0000 - val_accuracy: 0.0000e+00 - val_loss: -2779618738176.0000\n",
      "Epoch 16/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -3362695675904.0000 - val_accuracy: 0.0000e+00 - val_loss: -4856519065600.0000\n",
      "Epoch 17/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -5960835268608.0000 - val_accuracy: 0.0000e+00 - val_loss: -8143054569472.0000\n",
      "Epoch 18/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -9967452028928.0000 - val_accuracy: 0.0000e+00 - val_loss: -13178548256768.0000\n",
      "Epoch 19/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -15742361665536.0000 - val_accuracy: 0.0000e+00 - val_loss: -20658098536448.0000\n",
      "Epoch 20/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -24115677233152.0000 - val_accuracy: 0.0000e+00 - val_loss: -31505822777344.0000\n",
      "Epoch 21/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -37681123819520.0000 - val_accuracy: 0.0000e+00 - val_loss: -46873263996928.0000\n",
      "Epoch 22/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -54877216571392.0000 - val_accuracy: 0.0000e+00 - val_loss: -68145167466496.0000\n",
      "Epoch 23/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -80179892322304.0000 - val_accuracy: 0.0000e+00 - val_loss: -97307945074688.0000\n",
      "Epoch 24/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -112635089518592.0000 - val_accuracy: 0.0000e+00 - val_loss: -136152300388352.0000\n",
      "Epoch 25/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -157878870605824.0000 - val_accuracy: 0.0000e+00 - val_loss: -187476077445120.0000\n",
      "Epoch 26/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -216366225293312.0000 - val_accuracy: 0.0000e+00 - val_loss: -254332075245568.0000\n",
      "Epoch 27/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -285925301026816.0000 - val_accuracy: 0.0000e+00 - val_loss: -339661918568448.0000\n",
      "Epoch 28/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -386754523693056.0000 - val_accuracy: 0.0000e+00 - val_loss: -449370449248256.0000\n",
      "Epoch 29/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -497023715377152.0000 - val_accuracy: 0.0000e+00 - val_loss: -586166868901888.0000\n",
      "Epoch 30/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -651735584473088.0000 - val_accuracy: 0.0000e+00 - val_loss: -756841017507840.0000\n",
      "Epoch 31/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -848334155677696.0000 - val_accuracy: 0.0000e+00 - val_loss: -967451449753600.0000\n",
      "Epoch 32/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -1097734719275008.0000 - val_accuracy: 0.0000e+00 - val_loss: -1228266560028672.0000\n",
      "Epoch 33/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1379247411167232.0000 - val_accuracy: 0.0000e+00 - val_loss: -1540173393297408.0000\n",
      "Epoch 34/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -1716672658407424.0000 - val_accuracy: 0.0000e+00 - val_loss: -1917902479425536.0000\n",
      "Epoch 35/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -2187397987041280.0000 - val_accuracy: 0.0000e+00 - val_loss: -2366703342190592.0000\n",
      "Epoch 36/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -2640044724584448.0000 - val_accuracy: 0.0000e+00 - val_loss: -2900095867551744.0000\n",
      "Epoch 37/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -3279011572613120.0000 - val_accuracy: 0.0000e+00 - val_loss: -3534117060739072.0000\n",
      "Epoch 38/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -3945960669446144.0000 - val_accuracy: 0.0000e+00 - val_loss: -4276188893675520.0000\n",
      "Epoch 39/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -4776716060852224.0000 - val_accuracy: 0.0000e+00 - val_loss: -5144953671909376.0000\n",
      "Epoch 40/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -5650906188087296.0000 - val_accuracy: 0.0000e+00 - val_loss: -6150790452346880.0000\n",
      "Epoch 41/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -6741456366600192.0000 - val_accuracy: 0.0000e+00 - val_loss: -7317729845444608.0000\n",
      "Epoch 42/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -8190635777458176.0000 - val_accuracy: 0.0000e+00 - val_loss: -8678224624091136.0000\n",
      "Epoch 43/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -9604300640616448.0000 - val_accuracy: 0.0000e+00 - val_loss: -10221133106249728.0000\n",
      "Epoch 44/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -11398969905119232.0000 - val_accuracy: 0.0000e+00 - val_loss: -11992202599202816.0000\n",
      "Epoch 45/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -13695534015447040.0000 - val_accuracy: 0.0000e+00 - val_loss: -14002448083451904.0000\n",
      "Epoch 46/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -15398286684848128.0000 - val_accuracy: 0.0000e+00 - val_loss: -16284509162962944.0000\n",
      "Epoch 47/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -17503588385292288.0000 - val_accuracy: 0.0000e+00 - val_loss: -18878659746070528.0000\n",
      "Epoch 48/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -20896005885001728.0000 - val_accuracy: 0.0000e+00 - val_loss: -21790052719788032.0000\n",
      "Epoch 49/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -24570934522281984.0000 - val_accuracy: 0.0000e+00 - val_loss: -25084954060783616.0000\n",
      "Epoch 50/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -27359684704862208.0000 - val_accuracy: 0.0000e+00 - val_loss: -28786457808207872.0000\n",
      "Epoch 51/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -31510119908900864.0000 - val_accuracy: 0.0000e+00 - val_loss: -32851571339427840.0000\n",
      "Epoch 52/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -36395711780093952.0000 - val_accuracy: 0.0000e+00 - val_loss: -37450959474917376.0000\n",
      "Epoch 53/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -40041322970611712.0000 - val_accuracy: 0.0000e+00 - val_loss: -42467760449519616.0000\n",
      "Epoch 54/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -47208631250190336.0000 - val_accuracy: 0.0000e+00 - val_loss: -48117768452571136.0000\n",
      "Epoch 55/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -51603001269288960.0000 - val_accuracy: 0.0000e+00 - val_loss: -54293901359448064.0000\n",
      "Epoch 56/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -58802014997446656.0000 - val_accuracy: 0.0000e+00 - val_loss: -61161768814116864.0000\n",
      "Epoch 57/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -67356026482982912.0000 - val_accuracy: 0.0000e+00 - val_loss: -68742768343646208.0000\n",
      "Epoch 58/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -77378388502773760.0000 - val_accuracy: 0.0000e+00 - val_loss: -77031853361463296.0000\n",
      "Epoch 59/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -85562543174582272.0000 - val_accuracy: 0.0000e+00 - val_loss: -86117933985562624.0000\n",
      "Epoch 60/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -94543001962938368.0000 - val_accuracy: 0.0000e+00 - val_loss: -96066323783614464.0000\n",
      "Epoch 61/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -107947569123950592.0000 - val_accuracy: 0.0000e+00 - val_loss: -107059120779034624.0000\n",
      "Epoch 62/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -118072739775905792.0000 - val_accuracy: 0.0000e+00 - val_loss: -119005683982008320.0000\n",
      "Epoch 63/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -129759345788321792.0000 - val_accuracy: 0.0000e+00 - val_loss: -131926869753724928.0000\n",
      "Epoch 64/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -142815865979535360.0000 - val_accuracy: 0.0000e+00 - val_loss: -145966954635591680.0000\n",
      "Epoch 65/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -160677939178897408.0000 - val_accuracy: 0.0000e+00 - val_loss: -161404991242764288.0000\n",
      "Epoch 66/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -176159956251181056.0000 - val_accuracy: 0.0000e+00 - val_loss: -177839357183393792.0000\n",
      "Epoch 67/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -199851751770161152.0000 - val_accuracy: 0.0000e+00 - val_loss: -195922801587126272.0000\n",
      "Epoch 68/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -208439178101260288.0000 - val_accuracy: 0.0000e+00 - val_loss: -215166763334107136.0000\n",
      "Epoch 69/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -238933308463906816.0000 - val_accuracy: 0.0000e+00 - val_loss: -236009947563819008.0000\n",
      "Epoch 70/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -258696892534226944.0000 - val_accuracy: 0.0000e+00 - val_loss: -258577870400520192.0000\n",
      "Epoch 71/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -281809193885761536.0000 - val_accuracy: 0.0000e+00 - val_loss: -282798805890367488.0000\n",
      "Epoch 72/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -300394204570320896.0000 - val_accuracy: 0.0000e+00 - val_loss: -308699812327325696.0000\n",
      "Epoch 73/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -338905389607157760.0000 - val_accuracy: 0.0000e+00 - val_loss: -337097139656065024.0000\n",
      "Epoch 74/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -356569868541100032.0000 - val_accuracy: 0.0000e+00 - val_loss: -367343776823246848.0000\n",
      "Epoch 75/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -407459321123700736.0000 - val_accuracy: 0.0000e+00 - val_loss: -399560738827403264.0000\n",
      "Epoch 76/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -428586643209846784.0000 - val_accuracy: 0.0000e+00 - val_loss: -434001978494812160.0000\n",
      "Epoch 77/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -477817070185086976.0000 - val_accuracy: 0.0000e+00 - val_loss: -470767963700461568.0000\n",
      "Epoch 78/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -500768413342236672.0000 - val_accuracy: 0.0000e+00 - val_loss: -509910955606409216.0000\n",
      "Epoch 79/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -534164189250322432.0000 - val_accuracy: 0.0000e+00 - val_loss: -551407108554227712.0000\n",
      "Epoch 80/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -592800800762232832.0000 - val_accuracy: 0.0000e+00 - val_loss: -596616587146952704.0000\n",
      "Epoch 81/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -652464218695532544.0000 - val_accuracy: 0.0000e+00 - val_loss: -644220905144188928.0000\n",
      "Epoch 82/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -702603735628513280.0000 - val_accuracy: 0.0000e+00 - val_loss: -694892929302396928.0000\n",
      "Epoch 83/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -735341900503973888.0000 - val_accuracy: 0.0000e+00 - val_loss: -748519822240776192.0000\n",
      "Epoch 84/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -807318542998306816.0000 - val_accuracy: 0.0000e+00 - val_loss: -806036512440320000.0000\n",
      "Epoch 85/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -856393595236646912.0000 - val_accuracy: 0.0000e+00 - val_loss: -866132107162812416.0000\n",
      "Epoch 86/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -933505300630077440.0000 - val_accuracy: 0.0000e+00 - val_loss: -930819606040281088.0000\n",
      "Epoch 87/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -999002521101926400.0000 - val_accuracy: 0.0000e+00 - val_loss: -999452702394023936.0000\n",
      "Epoch 88/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -1071562317075841024.0000 - val_accuracy: 0.0000e+00 - val_loss: -1071917390612135936.0000\n",
      "Epoch 89/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -1176795063141793792.0000 - val_accuracy: 0.0000e+00 - val_loss: -1148008268178653184.0000\n",
      "Epoch 90/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1288943599907504128.0000 - val_accuracy: 0.0000e+00 - val_loss: -1228863948103614464.0000\n",
      "Epoch 91/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -1308524939925520384.0000 - val_accuracy: 0.0000e+00 - val_loss: -1313557954401665024.0000\n",
      "Epoch 92/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -1404604114251284480.0000 - val_accuracy: 0.0000e+00 - val_loss: -1403740860184526848.0000\n",
      "Epoch 93/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1487410533962350592.0000 - val_accuracy: 0.0000e+00 - val_loss: -1498641770362175488.0000\n",
      "Epoch 94/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1606221149119709184.0000 - val_accuracy: 0.0000e+00 - val_loss: -1598086000024748032.0000\n",
      "Epoch 95/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1744700103152631808.0000 - val_accuracy: 0.0000e+00 - val_loss: -1704223506721406976.0000\n",
      "Epoch 96/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -1825490705733124096.0000 - val_accuracy: 0.0000e+00 - val_loss: -1814833414402998272.0000\n",
      "Epoch 97/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -2015647256027332608.0000 - val_accuracy: 0.0000e+00 - val_loss: -1931791627345461248.0000\n",
      "Epoch 98/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -2084697685763293184.0000 - val_accuracy: 0.0000e+00 - val_loss: -2054900920650563584.0000\n",
      "Epoch 99/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -2230126927673294848.0000 - val_accuracy: 0.0000e+00 - val_loss: -2184085840332849152.0000\n",
      "Epoch 100/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -2391912779435999232.0000 - val_accuracy: 0.0000e+00 - val_loss: -2319635832828329984.0000\n",
      "Epoch 101/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -2492570320179822592.0000 - val_accuracy: 0.0000e+00 - val_loss: -2462224074131111936.0000\n",
      "Epoch 102/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -2624832223152439296.0000 - val_accuracy: 0.0000e+00 - val_loss: -2612046002433032192.0000\n",
      "Epoch 103/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -2777586548965638144.0000 - val_accuracy: 0.0000e+00 - val_loss: -2768651092844609536.0000\n",
      "Epoch 104/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -2924956566337617920.0000 - val_accuracy: 0.0000e+00 - val_loss: -2934184767429541888.0000\n",
      "Epoch 105/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -3232869300138147840.0000 - val_accuracy: 0.0000e+00 - val_loss: -3108622562054111232.0000\n",
      "Epoch 106/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -3317512179145506816.0000 - val_accuracy: 0.0000e+00 - val_loss: -3289235488858177536.0000\n",
      "Epoch 107/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -3610002063343222784.0000 - val_accuracy: 0.0000e+00 - val_loss: -3479645614021541888.0000\n",
      "Epoch 108/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -3819771839492653056.0000 - val_accuracy: 0.0000e+00 - val_loss: -3678347156369965056.0000\n",
      "Epoch 109/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -3914691853684834304.0000 - val_accuracy: 0.0000e+00 - val_loss: -3884095193862897664.0000\n",
      "Epoch 110/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -4263748312596742144.0000 - val_accuracy: 0.0000e+00 - val_loss: -4100878204930097152.0000\n",
      "Epoch 111/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -4345992057232293888.0000 - val_accuracy: 0.0000e+00 - val_loss: -4326450162193924096.0000\n",
      "Epoch 112/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -4730790065750409216.0000 - val_accuracy: 0.0000e+00 - val_loss: -4563736591217983488.0000\n",
      "Epoch 113/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -4908451903345524736.0000 - val_accuracy: 0.0000e+00 - val_loss: -4808931257624821760.0000\n",
      "Epoch 114/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -5097159434753277952.0000 - val_accuracy: 0.0000e+00 - val_loss: -5064590800826925056.0000\n",
      "Epoch 115/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -5521003575074881536.0000 - val_accuracy: 0.0000e+00 - val_loss: -5336288920143396864.0000\n",
      "Epoch 116/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -5679577341055991808.0000 - val_accuracy: 0.0000e+00 - val_loss: -5617252074191323136.0000\n",
      "Epoch 117/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -5984807816240562176.0000 - val_accuracy: 0.0000e+00 - val_loss: -5910341192226177024.0000\n",
      "Epoch 118/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: -6428109464083103744.0000 - val_accuracy: 0.0000e+00 - val_loss: -6212793751283171328.0000\n",
      "Epoch 119/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -6584701910110961664.0000 - val_accuracy: 0.0000e+00 - val_loss: -6528525112268816384.0000\n",
      "Epoch 120/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -7054020202089938944.0000 - val_accuracy: 0.0000e+00 - val_loss: -6858277445531860992.0000\n",
      "Epoch 121/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -7256107690496098304.0000 - val_accuracy: 0.0000e+00 - val_loss: -7202862740409417728.0000\n",
      "Epoch 122/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -7657368961494810624.0000 - val_accuracy: 0.0000e+00 - val_loss: -7561771373262012416.0000\n",
      "Epoch 123/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -8425267882333569024.0000 - val_accuracy: 0.0000e+00 - val_loss: -7935933530926743552.0000\n",
      "Epoch 124/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -8444641826970796032.0000 - val_accuracy: 0.0000e+00 - val_loss: -8318092986416103424.0000\n",
      "Epoch 125/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -9264737863314964480.0000 - val_accuracy: 0.0000e+00 - val_loss: -8721380657344806912.0000\n",
      "Epoch 126/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -9105392240171155456.0000 - val_accuracy: 0.0000e+00 - val_loss: -9132035605935423488.0000\n",
      "Epoch 127/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -9520573328377511936.0000 - val_accuracy: 0.0000e+00 - val_loss: -9567536768534708224.0000\n",
      "Epoch 128/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -10227295422246813696.0000 - val_accuracy: 0.0000e+00 - val_loss: -10021007249666736128.0000\n",
      "Epoch 129/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -10892056853865299968.0000 - val_accuracy: 0.0000e+00 - val_loss: -10490087497378299904.0000\n",
      "Epoch 130/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -11267092573518299136.0000 - val_accuracy: 0.0000e+00 - val_loss: -10970048512158334976.0000\n",
      "Epoch 131/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -11937847443019792384.0000 - val_accuracy: 0.0000e+00 - val_loss: -11478332946469879808.0000\n",
      "Epoch 132/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -12189334339594485760.0000 - val_accuracy: 0.0000e+00 - val_loss: -11995167183199010816.0000\n",
      "Epoch 133/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -13089059207045447680.0000 - val_accuracy: 0.0000e+00 - val_loss: -12542597529994264576.0000\n",
      "Epoch 134/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -14067497012417265664.0000 - val_accuracy: 0.0000e+00 - val_loss: -13098706322067554304.0000\n",
      "Epoch 135/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -14027692492468518912.0000 - val_accuracy: 0.0000e+00 - val_loss: -13682418353556160512.0000\n",
      "Epoch 136/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -15111682314595205120.0000 - val_accuracy: 0.0000e+00 - val_loss: -14286904557739966464.0000\n",
      "Epoch 137/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -15014360142374240256.0000 - val_accuracy: 0.0000e+00 - val_loss: -14907068698224230400.0000\n",
      "Epoch 138/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -15879964964992057344.0000 - val_accuracy: 0.0000e+00 - val_loss: -15552983401031008256.0000\n",
      "Epoch 139/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -16691870739220922368.0000 - val_accuracy: 0.0000e+00 - val_loss: -16227877931811078144.0000\n",
      "Epoch 140/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -17420745793366654976.0000 - val_accuracy: 0.0000e+00 - val_loss: -16916328341449998336.0000\n",
      "Epoch 141/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: -18235170548734754816.0000 - val_accuracy: 0.0000e+00 - val_loss: -17626221426853806080.0000\n",
      "Epoch 142/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -19172228233995223040.0000 - val_accuracy: 0.0000e+00 - val_loss: -18365354924486688768.0000\n",
      "Epoch 143/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -19553048484321951744.0000 - val_accuracy: 0.0000e+00 - val_loss: -19130743660279234560.0000\n",
      "Epoch 144/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -20533155348344733696.0000 - val_accuracy: 0.0000e+00 - val_loss: -19925083636742750208.0000\n",
      "Epoch 145/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -21314670621181870080.0000 - val_accuracy: 0.0000e+00 - val_loss: -20740510047203753984.0000\n",
      "Epoch 146/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -22008761525471281152.0000 - val_accuracy: 0.0000e+00 - val_loss: -21585374781986832384.0000\n",
      "Epoch 147/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -23154547199613861888.0000 - val_accuracy: 0.0000e+00 - val_loss: -22454802606534426624.0000\n",
      "Epoch 148/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -24117937088847937536.0000 - val_accuracy: 0.0000e+00 - val_loss: -23357121221915312128.0000\n",
      "Epoch 149/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: -24863416967596343296.0000 - val_accuracy: 0.0000e+00 - val_loss: -24291569766083067904.0000\n",
      "Epoch 150/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -26169680761859342336.0000 - val_accuracy: 0.0000e+00 - val_loss: -25245994237504258048.0000\n",
      "Epoch 151/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -27764467402367041536.0000 - val_accuracy: 0.0000e+00 - val_loss: -26249718611291668480.0000\n",
      "Epoch 152/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: -28484291276792922112.0000 - val_accuracy: 0.0000e+00 - val_loss: -27263153871775596544.0000\n",
      "Epoch 153/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -29590136091544911872.0000 - val_accuracy: 0.0000e+00 - val_loss: -28314522283417796608.0000\n",
      "Epoch 154/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -31131343530431086592.0000 - val_accuracy: 0.0000e+00 - val_loss: -29408721071008382976.0000\n",
      "Epoch 155/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -31842830907695169536.0000 - val_accuracy: 0.0000e+00 - val_loss: -30531337836130467840.0000\n",
      "Epoch 156/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -33126895562193371136.0000 - val_accuracy: 0.0000e+00 - val_loss: -31694777268968620032.0000\n",
      "Epoch 157/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -33692288630451601408.0000 - val_accuracy: 0.0000e+00 - val_loss: -32886823795338248192.0000\n",
      "Epoch 158/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -34709114784795590656.0000 - val_accuracy: 0.0000e+00 - val_loss: -34108073350541606912.0000\n",
      "Epoch 159/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -37141911804598812672.0000 - val_accuracy: 0.0000e+00 - val_loss: -35380375429645860864.0000\n",
      "Epoch 160/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -36894961493000323072.0000 - val_accuracy: 0.0000e+00 - val_loss: -36679081180979527680.0000\n",
      "Epoch 161/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -39065595358323146752.0000 - val_accuracy: 0.0000e+00 - val_loss: -38041840081700913152.0000\n",
      "Epoch 162/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -41509224766683217920.0000 - val_accuracy: 0.0000e+00 - val_loss: -39438197858743877632.0000\n",
      "Epoch 163/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -42150842578048647168.0000 - val_accuracy: 0.0000e+00 - val_loss: -40862914239690440704.0000\n",
      "Epoch 164/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -43390075745435910144.0000 - val_accuracy: 0.0000e+00 - val_loss: -42340508333840007168.0000\n",
      "Epoch 165/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -45342852376831197184.0000 - val_accuracy: 0.0000e+00 - val_loss: -43861581515798347776.0000\n",
      "Epoch 166/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -46235391935794642944.0000 - val_accuracy: 0.0000e+00 - val_loss: -45415934715706212352.0000\n",
      "Epoch 167/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -49833693271272980480.0000 - val_accuracy: 0.0000e+00 - val_loss: -47031469140630044672.0000\n",
      "Epoch 168/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -50920696854771400704.0000 - val_accuracy: 0.0000e+00 - val_loss: -48693121481269313536.0000\n",
      "Epoch 169/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -52938828457321693184.0000 - val_accuracy: 0.0000e+00 - val_loss: -50401797735205306368.0000\n",
      "Epoch 170/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -54427919045051285504.0000 - val_accuracy: 0.0000e+00 - val_loss: -52153592437136162816.0000\n",
      "Epoch 171/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -55626584631420125184.0000 - val_accuracy: 0.0000e+00 - val_loss: -53961924026967261184.0000\n",
      "Epoch 172/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -56265871478134669312.0000 - val_accuracy: 0.0000e+00 - val_loss: -55827645725721755648.0000\n",
      "Epoch 173/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -60519068327395459072.0000 - val_accuracy: 0.0000e+00 - val_loss: -57726656238518796288.0000\n",
      "Epoch 174/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -61724968700275064832.0000 - val_accuracy: 0.0000e+00 - val_loss: -59660837929265135616.0000\n",
      "Epoch 175/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -63995143552283705344.0000 - val_accuracy: 0.0000e+00 - val_loss: -61671176193397751808.0000\n",
      "Epoch 176/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -65179066886747324416.0000 - val_accuracy: 0.0000e+00 - val_loss: -63739252012128141312.0000\n",
      "Epoch 177/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -69227160836962779136.0000 - val_accuracy: 0.0000e+00 - val_loss: -65869437043688341504.0000\n",
      "Epoch 178/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: -70306696537485344768.0000 - val_accuracy: 0.0000e+00 - val_loss: -68044147898126958592.0000\n",
      "Epoch 179/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -75768173102788247552.0000 - val_accuracy: 0.0000e+00 - val_loss: -70289011992464195584.0000\n",
      "Epoch 180/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -74287773054964596736.0000 - val_accuracy: 0.0000e+00 - val_loss: -72574039047540834304.0000\n",
      "Epoch 181/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -77260562225401167872.0000 - val_accuracy: 0.0000e+00 - val_loss: -74966470796465143808.0000\n",
      "Epoch 182/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -82084278066128879616.0000 - val_accuracy: 0.0000e+00 - val_loss: -77379115967154487296.0000\n",
      "Epoch 183/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -84102031436679217152.0000 - val_accuracy: 0.0000e+00 - val_loss: -79869087591602061312.0000\n",
      "Epoch 184/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -86403845835288739840.0000 - val_accuracy: 0.0000e+00 - val_loss: -82461665641153691648.0000\n",
      "Epoch 185/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -87809575849446866944.0000 - val_accuracy: 0.0000e+00 - val_loss: -85071853468935782400.0000\n",
      "Epoch 186/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -92454687021358645248.0000 - val_accuracy: 0.0000e+00 - val_loss: -87768533279405244416.0000\n",
      "Epoch 187/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: -93164047943134609408.0000 - val_accuracy: 0.0000e+00 - val_loss: -90503124250800422912.0000\n",
      "Epoch 188/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -93488087213979729920.0000 - val_accuracy: 0.0000e+00 - val_loss: -93305585875954958336.0000\n",
      "Epoch 189/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -99549307789815840768.0000 - val_accuracy: 0.0000e+00 - val_loss: -96194469115052687360.0000\n",
      "Epoch 190/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -102342419168087769088.0000 - val_accuracy: 0.0000e+00 - val_loss: -99202310716182757376.0000\n",
      "Epoch 191/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -107232237647877373952.0000 - val_accuracy: 0.0000e+00 - val_loss: -102252549485679869952.0000\n",
      "Epoch 192/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -109543068041834659840.0000 - val_accuracy: 0.0000e+00 - val_loss: -105408024712094679040.0000\n",
      "Epoch 193/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -113706522752036372480.0000 - val_accuracy: 0.0000e+00 - val_loss: -108638662553384255488.0000\n",
      "Epoch 194/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -114546426490354925568.0000 - val_accuracy: 0.0000e+00 - val_loss: -111922622310574456832.0000\n",
      "Epoch 195/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -120565724886847193088.0000 - val_accuracy: 0.0000e+00 - val_loss: -115318934563937320960.0000\n",
      "Epoch 196/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -122622462541671956480.0000 - val_accuracy: 0.0000e+00 - val_loss: -118771242745479561216.0000\n",
      "Epoch 197/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -125002060790876864512.0000 - val_accuracy: 0.0000e+00 - val_loss: -122332613684404158464.0000\n",
      "Epoch 198/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -131669516893896572928.0000 - val_accuracy: 0.0000e+00 - val_loss: -125981083536434659328.0000\n",
      "Epoch 199/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -136599137694611668992.0000 - val_accuracy: 0.0000e+00 - val_loss: -129679796671808012288.0000\n",
      "Epoch 200/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -139946086273933901824.0000 - val_accuracy: 0.0000e+00 - val_loss: -133554211765299970048.0000\n",
      "Epoch 201/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -139935891602121162752.0000 - val_accuracy: 0.0000e+00 - val_loss: -137416963239444480000.0000\n",
      "Epoch 202/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -150433368917149745152.0000 - val_accuracy: 0.0000e+00 - val_loss: -141451018625196490752.0000\n",
      "Epoch 203/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -147941488540516352000.0000 - val_accuracy: 0.0000e+00 - val_loss: -145525008273269325824.0000\n",
      "Epoch 204/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -154423241527651205120.0000 - val_accuracy: 0.0000e+00 - val_loss: -149710488400398647296.0000\n",
      "Epoch 205/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -162275302662343753728.0000 - val_accuracy: 0.0000e+00 - val_loss: -153985917374773067776.0000\n",
      "Epoch 206/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -162610556951792189440.0000 - val_accuracy: 0.0000e+00 - val_loss: -158412392858524844032.0000\n",
      "Epoch 207/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -166696412529351983104.0000 - val_accuracy: 0.0000e+00 - val_loss: -162899121579478745088.0000\n",
      "Epoch 208/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -173344904255815811072.0000 - val_accuracy: 0.0000e+00 - val_loss: -167549774289994514432.0000\n",
      "Epoch 209/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -177055993494071410688.0000 - val_accuracy: 0.0000e+00 - val_loss: -172239376100412620800.0000\n",
      "Epoch 210/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -186881510874854457344.0000 - val_accuracy: 0.0000e+00 - val_loss: -177112728294064652288.0000\n",
      "Epoch 211/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -189199721190857375744.0000 - val_accuracy: 0.0000e+00 - val_loss: -182090894732169314304.0000\n",
      "Epoch 212/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -196307298604336283648.0000 - val_accuracy: 0.0000e+00 - val_loss: -187161771990728048640.0000\n",
      "Epoch 213/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -198727772297815392256.0000 - val_accuracy: 0.0000e+00 - val_loss: -192335264470483861504.0000\n",
      "Epoch 214/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -204086334574758461440.0000 - val_accuracy: 0.0000e+00 - val_loss: -197653839708547973120.0000\n",
      "Epoch 215/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -210632140711281033216.0000 - val_accuracy: 0.0000e+00 - val_loss: -203060059217485365248.0000\n",
      "Epoch 216/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -217932563668178829312.0000 - val_accuracy: 0.0000e+00 - val_loss: -208609690227056836608.0000\n",
      "Epoch 217/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -225541799858900303872.0000 - val_accuracy: 0.0000e+00 - val_loss: -214296681025263108096.0000\n",
      "Epoch 218/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -230636391384246910976.0000 - val_accuracy: 0.0000e+00 - val_loss: -220063082951273873408.0000\n",
      "Epoch 219/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -237477376810408738816.0000 - val_accuracy: 0.0000e+00 - val_loss: -225979915660150439936.0000\n",
      "Epoch 220/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -241874631673140740096.0000 - val_accuracy: 0.0000e+00 - val_loss: -232052263293659643904.0000\n",
      "Epoch 221/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -251928442852222173184.0000 - val_accuracy: 0.0000e+00 - val_loss: -238264451214035910656.0000\n",
      "Epoch 222/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -253836420981855354880.0000 - val_accuracy: 0.0000e+00 - val_loss: -244569684206401093632.0000\n",
      "Epoch 223/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -258887700545160609792.0000 - val_accuracy: 0.0000e+00 - val_loss: -251046775264234176512.0000\n",
      "Epoch 224/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -268669149499902394368.0000 - val_accuracy: 0.0000e+00 - val_loss: -257709974058231136256.0000\n",
      "Epoch 225/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -285136579129568657408.0000 - val_accuracy: 0.0000e+00 - val_loss: -264490371995655995392.0000\n",
      "Epoch 226/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -284174761541962301440.0000 - val_accuracy: 0.0000e+00 - val_loss: -271342387722467672064.0000\n",
      "Epoch 227/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -287377964369115611136.0000 - val_accuracy: 0.0000e+00 - val_loss: -278399176494836350976.0000\n",
      "Epoch 228/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -297082940091122319360.0000 - val_accuracy: 0.0000e+00 - val_loss: -285576911546260389888.0000\n",
      "Epoch 229/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -309560831361821966336.0000 - val_accuracy: 0.0000e+00 - val_loss: -292916617854595366912.0000\n",
      "Epoch 230/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -316549010608617422848.0000 - val_accuracy: 0.0000e+00 - val_loss: -300488118806251569152.0000\n",
      "Epoch 231/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -315148567046365642752.0000 - val_accuracy: 0.0000e+00 - val_loss: -308178296644963401728.0000\n",
      "Epoch 232/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -331265085341003939840.0000 - val_accuracy: 0.0000e+00 - val_loss: -315985919917707755520.0000\n",
      "Epoch 233/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -336067118812431908864.0000 - val_accuracy: 0.0000e+00 - val_loss: -323994199664474718208.0000\n",
      "Epoch 234/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: -346675699578424000512.0000 - val_accuracy: 0.0000e+00 - val_loss: -332110636171042750464.0000\n",
      "Epoch 235/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -365758753021360078848.0000 - val_accuracy: 0.0000e+00 - val_loss: -340505697720182243328.0000\n",
      "Epoch 236/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -364583700546709356544.0000 - val_accuracy: 0.0000e+00 - val_loss: -348899668553786982400.0000\n",
      "Epoch 237/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: -368739889684074725376.0000 - val_accuracy: 0.0000e+00 - val_loss: -357550731594244816896.0000\n",
      "Epoch 238/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -379449308860473409536.0000 - val_accuracy: 0.0000e+00 - val_loss: -366382431201006714880.0000\n",
      "Epoch 239/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -390733922151780319232.0000 - val_accuracy: 0.0000e+00 - val_loss: -375433997948951724032.0000\n",
      "Epoch 240/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -397806297600984350720.0000 - val_accuracy: 0.0000e+00 - val_loss: -384667890113061060608.0000\n",
      "Epoch 241/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -416607383486000529408.0000 - val_accuracy: 0.0000e+00 - val_loss: -394058176811105255424.0000\n",
      "Epoch 242/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -417899564735334973440.0000 - val_accuracy: 0.0000e+00 - val_loss: -403601445158991691776.0000\n",
      "Epoch 243/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -430769409911104208896.0000 - val_accuracy: 0.0000e+00 - val_loss: -413365988022944792576.0000\n",
      "Epoch 244/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -442881559633940447232.0000 - val_accuracy: 0.0000e+00 - val_loss: -423370980885752971264.0000\n",
      "Epoch 245/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -455416238481191469056.0000 - val_accuracy: 0.0000e+00 - val_loss: -433567623023329017856.0000\n",
      "Epoch 246/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -466203028091813494784.0000 - val_accuracy: 0.0000e+00 - val_loss: -443950988623580495872.0000\n",
      "Epoch 247/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -467179394417278582784.0000 - val_accuracy: 0.0000e+00 - val_loss: -454482480430325956608.0000\n",
      "Epoch 248/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -482976860825815351296.0000 - val_accuracy: 0.0000e+00 - val_loss: -465328696445406019584.0000\n",
      "Epoch 249/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -508727458332701360128.0000 - val_accuracy: 0.0000e+00 - val_loss: -476413955084457607168.0000\n",
      "Epoch 250/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -503350582590086053888.0000 - val_accuracy: 0.0000e+00 - val_loss: -487603077989915426816.0000\n",
      "Epoch 251/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -520971092054033563648.0000 - val_accuracy: 0.0000e+00 - val_loss: -499014319836370042880.0000\n",
      "Epoch 252/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -531231875301927550976.0000 - val_accuracy: 0.0000e+00 - val_loss: -510837711417473236992.0000\n",
      "Epoch 253/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -532977231263766151168.0000 - val_accuracy: 0.0000e+00 - val_loss: -522740971523218079744.0000\n",
      "Epoch 254/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -566855066879451463680.0000 - val_accuracy: 0.0000e+00 - val_loss: -534939885907625377792.0000\n",
      "Epoch 255/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -567061845434217529344.0000 - val_accuracy: 0.0000e+00 - val_loss: -547359019276936675328.0000\n",
      "Epoch 256/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -576309600240929865728.0000 - val_accuracy: 0.0000e+00 - val_loss: -560129644523415404544.0000\n",
      "Epoch 257/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -611856441731021012992.0000 - val_accuracy: 0.0000e+00 - val_loss: -573103705809311760384.0000\n",
      "Epoch 258/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -596613234735999614976.0000 - val_accuracy: 0.0000e+00 - val_loss: -586089166831764897792.0000\n",
      "Epoch 259/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -626821340342819749888.0000 - val_accuracy: 0.0000e+00 - val_loss: -599623961455640969216.0000\n",
      "Epoch 260/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -628457413644950437888.0000 - val_accuracy: 0.0000e+00 - val_loss: -613240594928995663872.0000\n",
      "Epoch 261/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -658031004285520576512.0000 - val_accuracy: 0.0000e+00 - val_loss: -627143910666130161664.0000\n",
      "Epoch 262/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -671160474942933303296.0000 - val_accuracy: 0.0000e+00 - val_loss: -641201615427990454272.0000\n",
      "Epoch 263/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -696803478639971663872.0000 - val_accuracy: 0.0000e+00 - val_loss: -655778289678161018880.0000\n",
      "Epoch 264/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -708961438415267561472.0000 - val_accuracy: 0.0000e+00 - val_loss: -670457772663575150592.0000\n",
      "Epoch 265/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -709196892233286025216.0000 - val_accuracy: 0.0000e+00 - val_loss: -685283693005623001088.0000\n",
      "Epoch 266/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -726715894783757254656.0000 - val_accuracy: 0.0000e+00 - val_loss: -700497204390601424896.0000\n",
      "Epoch 267/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -735538516822520233984.0000 - val_accuracy: 0.0000e+00 - val_loss: -716090495887906701312.0000\n",
      "Epoch 268/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -779246162312383430656.0000 - val_accuracy: 0.0000e+00 - val_loss: -732063145285073764352.0000\n",
      "Epoch 269/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -805948215609295634432.0000 - val_accuracy: 0.0000e+00 - val_loss: -748198205743802875904.0000\n",
      "Epoch 270/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -806588641550056554496.0000 - val_accuracy: 0.0000e+00 - val_loss: -764671036174584774656.0000\n",
      "Epoch 271/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -829856700131098755072.0000 - val_accuracy: 0.0000e+00 - val_loss: -781315636709904351232.0000\n",
      "Epoch 272/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -820028227263060246528.0000 - val_accuracy: 0.0000e+00 - val_loss: -798168317621757280256.0000\n",
      "Epoch 273/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -840005491522633990144.0000 - val_accuracy: 0.0000e+00 - val_loss: -815436877811700203520.0000\n",
      "Epoch 274/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -876404357767228293120.0000 - val_accuracy: 0.0000e+00 - val_loss: -832995990546352701440.0000\n",
      "Epoch 275/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -864679306506113384448.0000 - val_accuracy: 0.0000e+00 - val_loss: -850959723560026767360.0000\n",
      "Epoch 276/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -921038196667957903360.0000 - val_accuracy: 0.0000e+00 - val_loss: -869438555781081333760.0000\n",
      "Epoch 277/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -938701666250225876992.0000 - val_accuracy: 0.0000e+00 - val_loss: -887929139582413570048.0000\n",
      "Epoch 278/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -944688427898628997120.0000 - val_accuracy: 0.0000e+00 - val_loss: -906793029571608313856.0000\n",
      "Epoch 279/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -951680547795098402816.0000 - val_accuracy: 0.0000e+00 - val_loss: -925901239840587907072.0000\n",
      "Epoch 280/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -984568928498901581824.0000 - val_accuracy: 0.0000e+00 - val_loss: -945758806866315444224.0000\n",
      "Epoch 281/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1000960342292669923328.0000 - val_accuracy: 0.0000e+00 - val_loss: -965572745270652829696.0000\n",
      "Epoch 282/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -1052930544986386071552.0000 - val_accuracy: 0.0000e+00 - val_loss: -985987632750267465728.0000\n",
      "Epoch 283/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1047475700675221913600.0000 - val_accuracy: 0.0000e+00 - val_loss: -1006760697137746411520.0000\n",
      "Epoch 284/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -1074045742208056819712.0000 - val_accuracy: 0.0000e+00 - val_loss: -1027964418239592660992.0000\n",
      "Epoch 285/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1122644578368221085696.0000 - val_accuracy: 0.0000e+00 - val_loss: -1049638132183801528320.0000\n",
      "Epoch 286/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -1111331817579243110400.0000 - val_accuracy: 0.0000e+00 - val_loss: -1071088425365246312448.0000\n",
      "Epoch 287/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1157208087027173556224.0000 - val_accuracy: 0.0000e+00 - val_loss: -1093519869946760265728.0000\n",
      "Epoch 288/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1151108805756830351360.0000 - val_accuracy: 0.0000e+00 - val_loss: -1115917748637301473280.0000\n",
      "Epoch 289/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -1200074474180392779776.0000 - val_accuracy: 0.0000e+00 - val_loss: -1138828474735409496064.0000\n",
      "Epoch 290/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -1224448940526140391424.0000 - val_accuracy: 0.0000e+00 - val_loss: -1162292299162753957888.0000\n",
      "Epoch 291/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -1197273657424633397248.0000 - val_accuracy: 0.0000e+00 - val_loss: -1185746131228425191424.0000\n",
      "Epoch 292/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -1278773470293808644096.0000 - val_accuracy: 0.0000e+00 - val_loss: -1210220661928393441280.0000\n",
      "Epoch 293/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1324923263050357669888.0000 - val_accuracy: 0.0000e+00 - val_loss: -1234725591925846441984.0000\n",
      "Epoch 294/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -1333922299530774052864.0000 - val_accuracy: 0.0000e+00 - val_loss: -1259528885398612738048.0000\n",
      "Epoch 295/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1342386392817951834112.0000 - val_accuracy: 0.0000e+00 - val_loss: -1284692044629103607808.0000\n",
      "Epoch 296/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -1393574024707668180992.0000 - val_accuracy: 0.0000e+00 - val_loss: -1310560720888719736832.0000\n",
      "Epoch 297/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1408660661246894276608.0000 - val_accuracy: 0.0000e+00 - val_loss: -1336959696004458741760.0000\n",
      "Epoch 298/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1471892748127547949056.0000 - val_accuracy: 0.0000e+00 - val_loss: -1363619035473655103488.0000\n",
      "Epoch 299/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1508839716520542076928.0000 - val_accuracy: 0.0000e+00 - val_loss: -1390743230866889113600.0000\n",
      "Epoch 300/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1466227923483757641728.0000 - val_accuracy: 0.0000e+00 - val_loss: -1417926676742720716800.0000\n",
      "Epoch 301/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: -1468168974923154325504.0000 - val_accuracy: 0.0000e+00 - val_loss: -1446142291358150295552.0000\n",
      "Epoch 302/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1519713657820828139520.0000 - val_accuracy: 0.0000e+00 - val_loss: -1474211961198155399168.0000\n",
      "Epoch 303/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1560975919081773334528.0000 - val_accuracy: 0.0000e+00 - val_loss: -1503311407240456437760.0000\n",
      "Epoch 304/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1607965914643803668480.0000 - val_accuracy: 0.0000e+00 - val_loss: -1532552857408508002304.0000\n",
      "Epoch 305/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -1666450926042232127488.0000 - val_accuracy: 0.0000e+00 - val_loss: -1562662235667246874624.0000\n",
      "Epoch 306/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1649233383191818010624.0000 - val_accuracy: 0.0000e+00 - val_loss: -1593001578981958352896.0000\n",
      "Epoch 307/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -1725664535417876119552.0000 - val_accuracy: 0.0000e+00 - val_loss: -1623782556535128850432.0000\n",
      "Epoch 308/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1725826946479438168064.0000 - val_accuracy: 0.0000e+00 - val_loss: -1655329990449882464256.0000\n",
      "Epoch 309/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -1757362558445169934336.0000 - val_accuracy: 0.0000e+00 - val_loss: -1686909653249469448192.0000\n",
      "Epoch 310/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -1768662934335172640768.0000 - val_accuracy: 0.0000e+00 - val_loss: -1719201307002646036480.0000\n",
      "Epoch 311/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -1848810400678741540864.0000 - val_accuracy: 0.0000e+00 - val_loss: -1752341889285581963264.0000\n",
      "Epoch 312/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -1885405103138382282752.0000 - val_accuracy: 0.0000e+00 - val_loss: -1786161952162297413632.0000\n",
      "Epoch 313/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -1946830824355995320320.0000 - val_accuracy: 0.0000e+00 - val_loss: -1820398175792079568896.0000\n",
      "Epoch 314/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -1963917622079727337472.0000 - val_accuracy: 0.0000e+00 - val_loss: -1854970199069077536768.0000\n",
      "Epoch 315/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -2025439467001887064064.0000 - val_accuracy: 0.0000e+00 - val_loss: -1890061543678106664960.0000\n",
      "Epoch 316/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -2002517270798478082048.0000 - val_accuracy: 0.0000e+00 - val_loss: -1925603248249872842752.0000\n",
      "Epoch 317/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -2082968167166941069312.0000 - val_accuracy: 0.0000e+00 - val_loss: -1962166284774633635840.0000\n",
      "Epoch 318/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -2110017349478881689600.0000 - val_accuracy: 0.0000e+00 - val_loss: -1998803067743292620800.0000\n",
      "Epoch 319/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -2120728457505140637696.0000 - val_accuracy: 0.0000e+00 - val_loss: -2035750458348751814656.0000\n",
      "Epoch 320/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -2159279833265385504768.0000 - val_accuracy: 0.0000e+00 - val_loss: -2073820793373798170624.0000\n",
      "Epoch 321/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -2208190754805977710592.0000 - val_accuracy: 0.0000e+00 - val_loss: -2112356688010323951616.0000\n",
      "Epoch 322/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -2289380241513329459200.0000 - val_accuracy: 0.0000e+00 - val_loss: -2151704215742194909184.0000\n",
      "Epoch 323/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -2285214834070476816384.0000 - val_accuracy: 0.0000e+00 - val_loss: -2191721935393613938688.0000\n",
      "Epoch 324/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -2253776753184175292416.0000 - val_accuracy: 0.0000e+00 - val_loss: -2231619887442442584064.0000\n",
      "Epoch 325/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -2304731183055686860800.0000 - val_accuracy: 0.0000e+00 - val_loss: -2272394211831259856896.0000\n",
      "Epoch 326/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -2407743424707415769088.0000 - val_accuracy: 0.0000e+00 - val_loss: -2314521727170613608448.0000\n",
      "Epoch 327/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -2495768812699162509312.0000 - val_accuracy: 0.0000e+00 - val_loss: -2356883851903055691776.0000\n",
      "Epoch 328/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -2496589593731250782208.0000 - val_accuracy: 0.0000e+00 - val_loss: -2399805830364175269888.0000\n",
      "Epoch 329/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -2562017044692759216128.0000 - val_accuracy: 0.0000e+00 - val_loss: -2443627262113373749248.0000\n",
      "Epoch 330/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -2635483420989123985408.0000 - val_accuracy: 0.0000e+00 - val_loss: -2487856269628849258496.0000\n",
      "Epoch 331/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -2616199851809653653504.0000 - val_accuracy: 0.0000e+00 - val_loss: -2532864118404883152896.0000\n",
      "Epoch 332/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -2725134326971374764032.0000 - val_accuracy: 0.0000e+00 - val_loss: -2578736095359418761216.0000\n",
      "Epoch 333/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -2731125803325637787648.0000 - val_accuracy: 0.0000e+00 - val_loss: -2625459815593480814592.0000\n",
      "Epoch 334/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -2840118543807538003968.0000 - val_accuracy: 0.0000e+00 - val_loss: -2672519053999781969920.0000\n",
      "Epoch 335/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -2838697095175149191168.0000 - val_accuracy: 0.0000e+00 - val_loss: -2720759642883337748480.0000\n",
      "Epoch 336/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -2941937613032990441472.0000 - val_accuracy: 0.0000e+00 - val_loss: -2769196419825660854272.0000\n",
      "Epoch 337/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -2912174730470582386688.0000 - val_accuracy: 0.0000e+00 - val_loss: -2818152799574991831040.0000\n",
      "Epoch 338/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -3007053189720303468544.0000 - val_accuracy: 0.0000e+00 - val_loss: -2868009617774820196352.0000\n",
      "Epoch 339/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: -3038469174820933206016.0000 - val_accuracy: 0.0000e+00 - val_loss: -2919518694087940112384.0000\n",
      "Epoch 340/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -3125544584766281482240.0000 - val_accuracy: 0.0000e+00 - val_loss: -2970662978831243018240.0000\n",
      "Epoch 341/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: -3113382332497590747136.0000 - val_accuracy: 0.0000e+00 - val_loss: -3022495751367580188672.0000\n",
      "Epoch 342/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: -3167453112573754343424.0000 - val_accuracy: 0.0000e+00 - val_loss: -3075265835576363843584.0000\n",
      "Epoch 343/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: -3318200132575889981440.0000 - val_accuracy: 0.0000e+00 - val_loss: -3129591350506450583552.0000\n",
      "Epoch 344/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -3355128805095397916672.0000 - val_accuracy: 0.0000e+00 - val_loss: -3184279686681517359104.0000\n",
      "Epoch 345/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -3420582714704717152256.0000 - val_accuracy: 0.0000e+00 - val_loss: -3239541387384143740928.0000\n",
      "Epoch 346/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -3413415235897757007872.0000 - val_accuracy: 0.0000e+00 - val_loss: -3295150146733054361600.0000\n",
      "Epoch 347/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: -3575473609313987067904.0000 - val_accuracy: 0.0000e+00 - val_loss: -3352210472536861835264.0000\n",
      "Epoch 348/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: -3582116418764358549504.0000 - val_accuracy: 0.0000e+00 - val_loss: -3409975611682352791552.0000\n",
      "Epoch 349/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 350/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 351/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 352/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 353/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 354/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 355/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 356/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 357/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 358/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 359/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 360/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 361/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 362/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 363/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 364/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 365/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 366/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 367/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 368/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 369/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 370/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 371/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 372/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 373/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 374/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 375/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 376/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 377/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 378/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 379/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 380/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 381/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 382/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 383/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 384/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 385/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 386/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 387/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 388/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 389/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 390/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 391/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 392/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 393/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 394/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 395/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 396/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 397/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 398/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 399/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 400/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 401/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 402/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 403/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 404/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 405/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 406/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 407/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 408/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 409/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 410/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 411/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 412/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 413/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 414/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 415/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 416/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 417/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 418/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 419/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 420/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 421/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 422/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 423/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 424/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 425/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 426/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 427/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 428/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 429/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 430/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 431/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 432/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 433/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 434/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 435/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 436/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 437/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 438/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 439/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 440/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 441/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 442/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 443/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 444/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 445/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 446/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 447/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 448/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 449/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 450/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 451/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 452/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 453/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 454/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 455/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 456/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 457/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 458/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 459/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 460/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 461/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 462/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 463/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 464/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 465/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 466/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 467/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 468/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 469/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 470/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 471/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 472/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 473/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 474/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 475/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 476/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 477/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 478/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 479/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 480/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 481/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 482/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 483/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 484/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 485/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 486/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 487/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 488/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 489/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 490/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 491/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 492/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 493/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 494/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 495/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 496/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 497/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 498/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 499/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 500/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 501/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 502/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 503/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 504/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 505/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 506/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 507/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 508/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 509/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 510/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 511/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 512/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 513/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 514/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 515/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 516/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 517/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 518/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 519/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 520/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 521/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 522/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 523/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 524/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 525/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 526/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 527/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 528/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 529/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 530/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 531/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 532/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 533/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 534/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 535/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 536/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 537/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 538/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 539/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 540/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 541/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 542/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 543/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 544/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 545/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 546/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 547/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 548/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 549/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 550/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 551/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 552/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 553/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 554/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 555/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 556/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 557/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 558/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 559/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 560/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 561/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 562/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 563/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 564/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 565/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 566/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 567/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 568/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 569/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 570/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 571/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 572/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 573/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 574/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 575/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 576/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 577/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 578/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 579/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 580/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 581/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 582/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 583/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 584/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 585/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 586/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 587/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 588/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 589/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 590/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 591/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 592/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 593/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 594/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 595/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 596/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 597/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 598/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 599/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 600/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 601/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 602/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 603/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 604/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 605/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 606/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 607/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 608/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 609/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 610/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 611/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 612/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 613/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 614/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 615/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 616/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 617/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 618/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 619/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 620/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 621/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 622/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 623/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 624/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 625/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 626/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 627/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 628/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 629/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 630/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 631/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 632/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 633/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 634/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 635/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 636/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 637/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 638/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 639/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 640/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 641/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 642/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 643/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 644/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 645/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 646/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 647/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 648/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 649/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 650/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 651/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 652/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 653/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 654/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 655/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 656/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 657/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 658/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 659/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 660/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 661/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 662/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 663/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 664/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 665/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 666/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 667/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 668/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 669/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 670/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 671/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 672/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 673/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 674/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 675/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 676/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 677/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 678/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 679/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 680/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 681/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 682/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 683/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 684/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 685/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 686/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 687/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 688/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 689/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 690/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 691/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 692/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 693/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 694/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 695/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 696/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 697/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 698/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 699/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 700/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 701/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 702/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 703/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 704/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 705/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 706/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 707/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 708/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 709/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 710/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 711/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 712/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 713/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 714/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 715/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 716/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 717/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 718/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 719/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 720/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 721/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 722/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 723/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 724/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 725/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 726/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 727/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 728/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 729/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 730/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 731/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 732/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 733/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 734/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 735/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 736/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 737/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 738/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 739/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 740/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 741/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 742/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 743/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 744/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 745/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 746/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 747/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 748/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 749/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 750/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 751/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 752/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 753/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 754/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 755/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 756/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 757/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 758/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 759/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 760/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 761/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 762/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 763/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 764/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 765/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 766/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 767/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 768/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 769/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 770/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 771/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 772/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 773/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 774/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 775/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 776/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 777/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 778/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 779/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 780/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 781/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 782/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 783/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 784/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 785/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 786/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 787/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 788/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 789/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 790/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 791/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 792/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 793/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 794/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 795/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 796/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 797/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 798/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 799/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 800/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 801/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 802/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 803/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 804/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 805/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 806/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 807/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 808/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 809/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 810/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 811/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 812/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 813/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 814/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 815/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 816/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 817/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 818/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 819/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 820/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 821/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 822/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 823/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 824/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 825/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 826/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 827/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 828/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 829/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 830/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 831/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 832/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 833/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 834/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 835/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 836/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 837/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 838/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 839/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 840/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 841/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 842/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 843/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 844/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 845/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 846/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 847/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 848/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 849/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 850/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 851/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 852/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 853/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 854/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 855/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 856/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 857/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 858/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 859/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 860/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 861/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 862/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 863/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 864/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 865/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 866/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 867/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 868/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 869/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 870/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 871/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 872/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 873/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 874/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 875/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 876/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 877/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 878/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 879/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 880/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 881/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 882/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 883/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 884/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 885/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 886/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 887/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 888/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 889/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 890/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 891/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 892/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 893/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 894/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 895/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 896/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 897/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 898/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 899/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 900/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 901/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 902/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 903/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 904/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 905/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 906/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 907/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 908/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 909/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 910/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 911/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 912/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 913/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 914/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 915/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 916/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 917/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 918/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 919/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 920/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 921/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 922/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 923/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 924/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 925/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 926/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 927/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 928/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 929/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 930/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 931/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 932/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 933/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 934/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 935/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 936/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 937/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 938/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 939/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 940/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 941/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 942/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 943/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 944/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 945/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 946/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 947/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 948/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 949/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 950/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 951/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 952/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 953/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 954/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 955/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 956/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 957/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 958/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 959/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 960/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 961/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 962/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 963/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 964/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 965/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 966/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 967/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 968/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 969/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 970/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 971/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 972/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 973/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 974/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 975/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 976/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 977/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 978/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 979/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 980/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 981/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 982/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 983/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 984/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 985/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 986/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 987/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 988/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 989/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 990/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 991/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 992/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 993/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 994/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 995/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 996/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 997/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 998/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 999/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 1000/1000\n",
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=2000, epochs=1000, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce9661",
   "metadata": {},
   "source": [
    "## Evaluate the Model\n",
    "Evaluate the performance of the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "73167afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m185/185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.0000e+00 - loss: -221388880.0000\n",
      "Test Loss: -225538640.0\n",
      "Test Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e9bc87",
   "metadata": {},
   "source": [
    "## Make Predictions\n",
    "Use the trained model to make predictions on new or unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940fa394",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = np.array([3])\n",
    "predictions = model.predict(new_data)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94942463",
   "metadata": {},
   "source": [
    "## Model Performance Visualization\n",
    "Visualize the performance metrics such as accuracy and loss over the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1955952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy', c=\"red\")\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy', c=\"pink\")\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss', c='red')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss',c='pink')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d32965f",
   "metadata": {},
   "source": [
    "## Save the Model\n",
    "Save the trained model for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e1f00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ANN_Task\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebe9b8d",
   "metadata": {},
   "source": [
    "## Project Questions:\n",
    "\n",
    "1. **Data Preprocessing**: Explain why you chose your specific data preprocessing techniques (e.g., normalization, encoding). How did these techniques help prepare the data for training the model?\n",
    "2. **Model Architecture**: Describe the reasoning behind your model’s architecture (e.g., the number of layers, type of layers, number of neurons, and activation functions). Why did you believe this architecture was appropriate for the problem at hand?\n",
    "3. **Training Process**: Discuss why you chose your batch size, number of epochs, and optimizer. How did these choices affect the training process? Did you experiment with different values, and what were the outcomes?\n",
    "4. **Loss Function and Metrics**: Why did you choose the specific loss function and evaluation metrics? How do they align with the objective of the task (e.g., regression vs classification)?\n",
    "5. **Regularization Techniques**: If you used regularization techniques such as dropout or weight decay, explain why you implemented them and how they influenced the model's performance.\n",
    "6. **Model Evaluation**: Justify your approach to evaluating the model. Why did you choose the specific performance metrics, and how do they reflect the model's success in solving the task?\n",
    "7. **Model Tuning (If Done)**: Describe any tuning you performed (e.g., hyperparameter tuning) and why you felt it was necessary. How did these adjustments improve model performance?\n",
    "8. **Overfitting and Underfitting**: Analyze whether the model encountered any overfitting or underfitting during training. What strategies could you implement to mitigate these issues?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f524a61",
   "metadata": {},
   "source": [
    "### Answer Here:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
